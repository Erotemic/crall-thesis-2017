
\begin{comment}
        python -m ibeis.scripts.gen_cand_expts --exec-parse_latex_comments_for_commmands --fname figdef3.tex
\end{comment}

            
\begin{comment}
ibeis ChipMatch.show_ranked_matches --qaid 79 --db PZ_MTEST --show --heatmask=True
ibeis ChipMatch.show_ranked_matches --qaid 79 --db PZ_MTEST \
    --clip-top=4 --colorbar_=False --show_aid=False --score_precision=2 --stack_larger=True --noshow_truth --draw_lbl=False --stack_side=True --show_timedelta=False \
    --dpath ~/latex/crall-thesis-2017 --save figures3/rankedmatches.jpg \
    --diskshow --saveparts --dpi=300 --figsize=14,14 
\end{comment}
\newcommand{\rankedmatches}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{0.7\textwidth}\centering\includegraphics[width=\textwidth]{figures3/rankedmatchesA.jpg}\caption{}\label{sub:rankedmatchesa}\end{subfigure}
\begin{subfigure}[h]{0.7\textwidth}\centering\includegraphics[width=\textwidth]{figures3/rankedmatchesB.jpg}\caption{}\label{sub:rankedmatchesb}\end{subfigure}
\begin{subfigure}[h]{0.7\textwidth}\centering\includegraphics[width=\textwidth]{figures3/rankedmatchesC.jpg}\caption{}\label{sub:rankedmatchesc}\end{subfigure}
\caption[\caplbl{rankedmatches}Ranked matches]{\caplbl{rankedmatches}
    % ---
    The top three ranked results from the ranking algorithm.
    Each results shows the matches to a particular \name{}.
    The top-ranked match in \cref{sub:rankedmatchesa} is correct.
    The other ranks in \cref{sub:rankedmatchesb,sub:rankedmatchesc} are incorrect.
    In each result, the query annotation is on the left and the matching exemplars for the name are on the right.
    The overall matching score is shown on the top of each result.
    The feature matches are overlaid on each result and colored by the feature correspondence score.
    Notice that each database \name{} may have a different number exemplars.
    % ---
}
\label{fig:rankedmatches}
\end{figure}
}



\begin{comment}
python -m ibeis.viz.viz_name --test-show_multiple_chips --db GZ_Master1 --aids 2811 2810 --show --notitle --no-inimage  --dpath ~/latex/crall-candidacy-2015/ --save figures3/SceneryMatch.jpg --diskshow --clipwhite --figsize=12,6 --dpi 300
python -m ibeis.viz.viz_name --test-show_multiple_chips --db GZ_Master1 --tags SceneryMatch --index 5 --show --notitle --no-inimage 

python -m ibeis.scripts.specialdraw simple_vsone_matches \
    --db GZ_Master1 --aids=2811,2810 \
    --figsize=12,6 --dpi 300 \
    --dpath ~/latex/crall-thesis-2017/ --save figures3/SceneryMatch2.jpg \
    --diskshow

\end{comment}
\newcommand{\SceneryMatch}{
\begin{figure}[ht!]
\centering
\includegraphics[width=\textwidth]{figures3/SceneryMatch2.jpg}
\caption[A scenery match]{\caplbl{SceneryMatch}
% ---
An example of two different animals with appearing in front of the same
distinctive background, illustrating the importance of background
downweighting. The matching regions are highlighted.
% ---
}
\label{fig:SceneryMatch}
\end{figure}
}



\begin{comment}
python -m ibeis gen_featweight_worker --dpath ~/latex/crall-candidacy-2015/ --saveparts --save figures3/genfeatweight.png --figsize=12,3 --dpi=180 --adjust=.15,.15,.1 --diskshow --clipwhite --label genfeatweight --db PZ_MTEST

python -m ibeis.scripts.specialdraw featweight_fig --db PZ_MTEST --aid=1 \
--dpath ~/latex/crall-thesis-2017/ --save figures3/fgweight.png \
--figsize=12,3 --dpi=300 --saveparts --diskshow 
\end{comment}
\newcommand{\fgweight}{
\begin{figure}[ht!]
\centering
\begin{subfigure}[h]{0.32\textwidth}\centering\includegraphics[width=\textwidth]{figures3/fgweightA.png}\caption{}\label{sub:fgweightA}\end{subfigure}
\begin{subfigure}[h]{0.32\textwidth}\centering\includegraphics[width=\textwidth]{figures3/fgweightB.png}\caption{}\label{sub:fgweightB}\end{subfigure}
\begin{subfigure}[h]{0.32\textwidth}\centering\includegraphics[width=\textwidth]{figures3/fgweightC.png}\caption{}\label{sub:fgweightC}\end{subfigure}
\caption[Foregroundness weights]{\caplbl{fgweight}
% ---
Generation of foregroundness feature weights. \Cref{sub:fgweightA} shows the annotation's cropped chip.
This chip is passed to the species detector. \Cref{sub:fgweightB} shows the species detector outputs an
intensity image indicating the likelihood that each pixel belongs to the foreground. \Cref{sub:fgweightC}
shows the weighted sum of the intensity under each feature is used as that feature's foregroundness score.
}
\label{fig:fgweight}
\end{figure}
}



\begin{comment}
python -m ibeis.viz.viz_nearest_descriptors --test-show_nearest_descriptors --db PZ_MTEST --qaid 3 --qfx 1062 --usetex --texknormplot --show 

python -m ibeis.viz.viz_nearest_descriptors --test-show_nearest_descriptors --db PZ_MTEST --qaid 3 --qfx 1062 --usetex --texknormplot --diskshow --saveparts --save figures3/knorm.png --dpi=256 --figsize 30 40  --dpath ~/latex/crall-candidacy-2015/ --hspace .1 --labelsize=42 --reshape 2

879?
%python -m ibeis.viz.viz_nearest_descriptors --test-show_nearest_descriptors --db PZ_MTEST --qaid 3 --qfx 'special' --usetex --texknormplot --show 
python -m ibeis.viz.viz_nearest_descriptors --test-show_nearest_descriptors --db testdb1  --show --qfx 1 

python -m ibeis.viz.interact.interact_matches --test-testdata_match_interact --show --db PZ_MTEST --qaid 3
\end{comment}
\newcommand{\knorm}{
\begin{figure}[ht!]
\centering
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormA.png}\caption{}\label{sub:knorma}\end{subfigure}
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormC.png}\caption{}\label{sub:knormb}\end{subfigure}
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormE.png}\caption{}\label{sub:knormc}\end{subfigure}
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormG.png}\caption{}\label{sub:knormd}\end{subfigure}
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormI.png}\caption{}\label{sub:knorme}\end{subfigure}
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormB.png}\caption{}\label{sub:knormf}\end{subfigure}
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormD.png}\caption{}\label{sub:knormg}\end{subfigure}
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormF.png}\caption{}\label{sub:knormh}\end{subfigure}
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormH.png}\caption{}\label{sub:knormi}\end{subfigure}
\begin{subfigure}[h]{0.18\textwidth}\centering\includegraphics[width=\textwidth]{figures3/knormJ.png}\caption{}\label{sub:knormj}\end{subfigure}
\caption[\caplbl{knorm}LNBNN feature correspondence scoring]{
% ---
\caplbl{knorm} The four nearest neighbors of a distinctive query feature~\cref{sub:knormf}. The bottom row shows
the warped and normalized features with their SIFT descriptors overlaid. The top row shows the annotation from
which each feature was extracted. The first two neighbors~\cref{sub:knormg,sub:knormh} are correct matches, the
third neighbor~\cref{sub:knormi} is an incorrect match, and the fourth neighbor~\cref{sub:knormj} is used as an
LNBNN normalizer to score the first three matches. 
% ---
}
\label{fig:knorm}
\end{figure}
}



\begin{comment}
python -m ibeis.algo.hots.chip_match --test-show_single_namematch --qaid 1 \
    --noshow_truth --show_timedelta=False --show_aid=False \
    --dpath ~/latex/crall-thesis-2017 --save figures3/namematch.jpg --diskshow --dpi=300 --figsize=5,5
#
python -m ibeis.algo.hots.chip_match --test-show_single_namematch --qaid 2 --dpath ~/latex/crall-candidacy-2015 --save figures3/namematch.jpg --diskshow --dpi=180 --clipwhite
python -m ibeis.algo.hots.chip_match --test-show_single_namematch --qaid 3 --dpath ~/latex/crall-candidacy-2015 --save figures3/namematch.jpg --diskshow --dpi=180 --clipwhite
python -m ibeis.algo.hots.chip_match --test-show_single_namematch --qaid 4 --dpath ~/latex/crall-candidacy-2015 --save figures3/namematch.jpg --diskshow --dpi=180 --clipwhite
--verbose 
\end{comment}
\SingleImageCommand{namematch}{1}{Name scoring}{
    % ---
    \Nsumprefix{} \namescoring{}.
    The query annotation is at the top left.
    Each query feature matches at most one feature in the exemplars for a name.
    Each line denotes a feature correspondence colored by its matching score.
    In the top right of each database annotation is its annotation score.
    Feature scores from multiple views are combined into a name score shown on top.
    % ---
}{figures3/namematch.jpg}


\begin{comment}
ibeis sver_single_chipmatch -t default:refine_method=cv2-lmeds-homog,full_homog_checks=True -a default --qaid 18 --dpath ~/latex/crall-candidacy-2015 --save figures3/sverkpts.jpg --label sver --dpi=300 --clipwhite --diskshow --saveparts --figsize=10,10 --norefinelbl
\end{comment}
\newcommand{\sver}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{0.25\textwidth}\centering\includegraphics[height=130pt]{figures3/sverkptsA.jpg}\caption{}\label{sub:svera}\end{subfigure}
\begin{subfigure}[h]{0.25\textwidth}\centering\includegraphics[height=130pt]{figures3/sverkptsB.jpg}\caption{}\label{sub:sverb}\end{subfigure}
\begin{subfigure}[h]{0.25\textwidth}\centering\includegraphics[height=130pt]{figures3/sverkptsC.jpg}\caption{}\label{sub:sverc}\end{subfigure}
\begin{subfigure}[h]{0.35\textwidth}\centering\includegraphics[width=\textwidth]{figures3/sverkptsD.jpg}\caption{}\label{sub:sverd}\end{subfigure}
\begin{subfigure}[h]{0.35\textwidth}\centering\includegraphics[width=\textwidth]{figures3/sverkptsE.jpg}\caption{}\label{sub:svere}\end{subfigure}
\begin{subfigure}[h]{0.35\textwidth}\centering\includegraphics[width=\textwidth]{figures3/sverkptsF.jpg}\caption{}\label{sub:sverf}\end{subfigure}
\begin{subfigure}[h]{0.35\textwidth}\centering\includegraphics[width=\textwidth]{figures3/sverkptsG.jpg}\caption{}\label{sub:sverg}\end{subfigure}
\caption[Spatial verification]{
    % ---
    An example of spatial verification process. The three images on the top show~\cref{sub:svera} the original
    matches, \Cref{sub:sverb} the best set of inliers from affine hypothesis generation, and \Cref{sub:sverc} the
    final set of homography inliers. The images on the bottom show~\cref{sub:sverd,sub:sverf} the matching images
    warped and superimposed by both the best affine \Cref{sub:svere} and estimated homography
    transformation~\cref{sub:sverg}.
    % ---
}
\label{fig:sver}
\end{figure}
}


\begin{comment}
ALL DATABASE INFO
python -m ibeis Chap3.measure dbstats --dbs=PZ_Master1,GZ_Master1,GIRM_Master1,humpbacks_fb
python -m ibeis Chap3.agg_dbstats
\end{comment}

\newcommand{\DatabaseInfo}{
\begin{table}[ht!]
\centering
\caption[Database statistics]{Database statistics.}
\label{tbl:DatabaseStatistics}
\input{figuresY/agg-enc.tex}
\end{table}
%--
\begin{table}[h!]
\centering
\caption[Annotations per quality]{Annotations per quality.}
\label{tbl:AnnotationsPerQuality}
\input{figuresY/agg-qual.tex}
\end{table}
%--
\begin{table}[h!]
\centering
\caption[Annotations per viewpoint]{Annotations per viewpoint.}
\label{tbl:AnnotationsPerViewpoint}
\input{figuresY/agg-view.tex}
\end{table}
}

%-------------
% TimeDeltas
\begin{comment}
python -m ibeis Chap3.measure time_distri --dbs=GIRM_Master1,GZ_Master1,PZ_Master1,humpbacks_fb --diskshow
python -m ibeis Chap3.draw time_distri --dbs=GIRM_Master1,GZ_Master1,PZ_Master1,humpbacks_fb --diskshow
\end{comment}
\newcommand{\timedist}{
\begin{figure}[ht!] \centering
\begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=.9\textwidth]{figuresY/PZ_Master1/timedist.png}\caption{plains zebras}\end{subfigure}
\begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=.9\textwidth]{figuresY/GZ_Master1/timedist.png}\caption{Grévy's zebras}\end{subfigure}
\begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=.9\textwidth]{figuresY/GIRM_Master1/timedist.png}\caption{Masai giraffes}\end{subfigure}
\begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=.9\textwidth]{figuresY/humpbacks_fb/timedist.png}\caption{Humpbacks}\end{subfigure}
\caption[\caplbl{timedist}Distribution of image timestamps]{\caplbl{timedist}
% ---
Distribution of image timestamps.
The y-axis is plotted on a square-root scale to emphasize times when only a few images were taken.
For plains zebras and Grévy's zebras images were collected over many years.
For Masai giraffes all data was collected immediately before and during the \GZC{}.
% ---
}
\label{fig:timedist}
\end{figure}
}


% -------------------------------
% --- Baseline Experiments ---
% -------------------------------


\begin{comment}                                                                                                                                       
\end{comment}
                                                                                                                                                      
\begin{comment}                                                                                                                                       
python -m ibeis Chap3.draw_agg_baseline --diskshow

python -m ibeis Chap3.draw_all --dbs=GZ_Master1,PZ_Master1,GIRM_Master1
python -m ibeis Chap3.draw_all --db GZ_Master1
python -m ibeis Chap3.draw_all --db PZ_Master1
python -m ibeis Chap3.draw_all --db GIRM_Master1
\end{comment}

\newcommand{\BaselineExpt}{
    \begin{figure}[ht!]\centering
        \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/agg-baseline.png}\end{subfigure}
        \caption[\caplbl{BaselineExpt}Baseline experiment]{\caplbl{BaselineExpt}
    % ---
    The baseline experiment is a high-level indicator of the ranking accuracy of each species.
    We measure ranking accuracy using a single query and database annotation --- selected from different
      encounters --- per individual.
    The number of query annotations (\pvar{qsize}) and database annotations (\pvar{dsize}) are given for each
      species in the legend.
    % ---
        }
        \label{fig:BaselineExpt}
    \end{figure}
}

\begin{comment}
python -m ibeis Chap3.draw_all --dbs=GZ_Master1,PZ_Master1
\end{comment}



\begin{comment}

ibeis Chap3.measure smk --db=GZ_Master1
ibeis Chap3.draw smk --db=GZ_Master1 --diskshow

ibeis Chap3.measure smk --db=PZ_Master1
ibeis Chap3.draw smk --db=PZ_Master1 --diskshow

ibeis Chap3.measure smk --dbs=GZ_Master1,PZ_Master1
ibeis Chap3.draw smk --dbs=GZ_Master1,PZ_Master1 --diskshow
\end{comment}
\newcommand{\SMKExpt}{
\begin{figure}[ht!]\centering
    \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/PZ_Master1/smk.png}\caption{plains zebras}\label{sub:SMKExptA}\end{subfigure}
    \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/GZ_Master1/smk.png}\caption{Grévy's zebras}\label{sub:SMKExptB}\end{subfigure}
    \caption[\caplbl{SMKExpt}SMK experiment]{\caplbl{SMKExpt}
    % ---
    The (VLAD based) SMK algorithm compared to our LNBNN ranking algorithm.
    The results demonstrate that LNBNN outperforms the ranking accuracy of SMK.
    The number of query/database annotations (\pvar{qsize} / \pvar{dsize}) are
    shown in the lower left.
    % ---
    }
    \label{fig:SMKExpt}
\end{figure}
}



\begin{comment}
python -m ibeis Chap3.measure foregroundness --dbs=GZ_Master1,PZ_Master1
python -m ibeis Chap3.draw foregroundness --dbs=GZ_Master1,PZ_Master1 --diskshow

python -m ibeis -e draw_rank_cmc --db GZ_Master1   -a timectrl   -t baseline:fg_on=[True,False]  --show
\end{comment}
\newcommand{\ForegroundExpt}{
    \begin{figure}[ht!]\centering
        \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/PZ_Master1/foregroundness.png}\caption{plains zebras}\label{sub:ForegroundExptA}\end{subfigure}
        \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/GZ_Master1/foregroundness.png}\caption{Grévy's zebras}\label{sub:ForegroundExptB}\end{subfigure}
        \caption[\caplbl{ForegroundExpt}Foregroundness experiment]{\caplbl{ForegroundExpt}
            % ---
            Weighting the score of the feature correspondences using foregroundness results in more accurate
              identifications.
            % ---
        }
        \label{fig:ForegroundExpt}
    \end{figure}
}


\newcommand{\FGIntraExpt}{
    \begin{figure}[ht!]\centering
        \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/PZ_Master1/foregroundness_intra.png}\caption{plains zebras}\end{subfigure}
        \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/GZ_Master1/foregroundness_intra.png}\caption{Grévy's zebras}\end{subfigure}
        \caption[\caplbl{FGIntraExpt}Foregroundness experiment]{\caplbl{FGIntraExpt}
            % ---
            Applying foregroundness weights to feature correspondences improves the identification accuracy at
              the top rank by filtering matches in scenery.
            This experiment was performed by matching annotations within serveral occurrences.
            Thus, in this experiment \pvar{qsize} is a sum and \pvar{dsize} is an average.
            % ---
        }
        \label{fig:FGIntraExpt}
    \end{figure}
}

% -------------------------------
% --- Invariance Experiments ----
% -------------------------------


\newcommand{\InvarExpt}{
    \begin{figure}[ht!]\centering
        \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/PZ_Master1/invar.png}\caption{plains zebras}\label{sub:InvarExptA}\end{subfigure}
        \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/GZ_Master1/invar.png}\caption{Grévy's zebras}\label{sub:InvarExptB}\end{subfigure}
        \caption[\caplbl{InvarExpt}Feature invariance experiment]{\caplbl{InvarExpt}
            % ---
            Results of the feature invariance experiment, testing the effect of affine invariance (AI) and the
              query-side rotation heuristic (QRH).
            For plains zebras circular keypoints with the QRH are the most accurate.
            For Grévy's zebras enabling affine invariance works the best.
            The number of query/database annotations (\pvar{qsize} / \pvar{dsize}) are shown in the lower left.
            % ---
        }
        \label{fig:InvarExpt}
    \end{figure}
}



% TODO; http://tex.stackexchange.com/questions/75014/is-it-possible-to-make-a-reference-to-a-subfigure-to-appear-figure-2a-with-cle

\begin{comment}
    python -m ibeis.viz.viz_chip --test-show_chip --aid 44 \
        --weight_label=None --ecc --dpi=300 --draw_lbls=False \
        --ellalpha=.8 --ell_linewidth=1.4 --notitle \
        --dpath ~/latex/crall-thesis-2017/figures3 --save=pzaffkpts.jpg --diskshow --darken

    python -m ibeis.viz.viz_chip --test-show_chip --aid 44 \
        --weight_label=None --ecc --dpi=300 --draw_lbls=False \
        --ellalpha=.8 --ell_linewidth=1.4 --notitle \
        --affine-invariance=False --augment_orientation=True --ori \
        --dpath ~/latex/crall-thesis-2017/figures3 --save=pzcirckpts.jpg --diskshow --darken

    python -m ibeis.viz.viz_chip --test-show_chip --db GZ_Master1 --aid 1000 \
        --weight_label=None --ecc --dpi=300 --draw_lbls=False \
        --ellalpha=.8 --ell_linewidth=1.4 --notitle \
        --dpath ~/latex/crall-thesis-2017/figures3 --save=gzaffkpts.jpg --diskshow --darken

    python -m ibeis.viz.viz_chip --test-show_chip --db GZ_Master1 --aid 1000 \
        --weight_label=None --ecc --dpi=300 --draw_lbls=False \
        --ellalpha=.8 --ell_linewidth=1.4 --notitle \
        --affine-invariance=False --augment_orientation=True --ori \
        --dpath ~/latex/crall-thesis-2017/figures3 --save=gzcirckpts.jpg --diskshow --darken 
\end{comment}
\newcommand{\kptstype}{
    \begin{figure}[ht!]\centering
        \begin{subfigure}[h]{.48\textwidth}\centering\includegraphics[width=\textwidth]{figures3/pzaffkpts.jpg}\caption{}\label{sub:kptstypeA}\end{subfigure}
        \begin{subfigure}[h]{.48\textwidth}\centering\includegraphics[width=\textwidth]{figures3/pzcirckpts.jpg}\caption{}\label{sub:kptstypeB}\end{subfigure}
        \begin{subfigure}[h]{.48\textwidth}\centering\includegraphics[width=\textwidth]{figures3/gzaffkpts.jpg}\caption{}\label{sub:kptstypeC}\end{subfigure}
        \begin{subfigure}[h]{.48\textwidth}\centering\includegraphics[width=\textwidth]{figures3/gzcirckpts.jpg}\caption{}\label{sub:kptstypeD}\end{subfigure}
        \caption[\caplbl{kptstype}Examples of keypoint invariance]{\caplbl{kptstype}
            % ---
            Many affine keypoints detected on plains zebras tend to encompass only one or two stripes. The distinctive stripe
            patterns on Grévy's zebras are well captured by affine keypoints, whereas circular keypoints are more spread out.
            For visibility this figure shows a random sample of all keypoints on a darkened image. Elliptical keypoints
            in~\cref{sub:kptstypeA,sub:kptstypeC} are colored by eccentricity and circular keypoints
            in~\cref{sub:kptstypeB,sub:kptstypeD} are colored by scale.
            % ---
        }
        \label{fig:kptstype}
    \end{figure}
}

% -------------------------------
% --- Namescore Experiments ----
% -------------------------------

\begin{comment}
python -m ibeis Chap3.measure nsum --dbs=GZ_Master1
python -m ibeis Chap3.measure nsum --dbs=GZ_Master1,PZ_Master1
python -m ibeis Chap3.draw nsum --dbs=GZ_Master1,PZ_Master1 --diskshow
\end{comment}

\newcommand{\NScoreExpt}{
    \begin{figure}[ht!]\centering
        \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/PZ_Master1/nsum.png}\caption{plains zebras}\label{sub:NScoreExptA}\end{subfigure}
        \begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figuresY/GZ_Master1/nsum.png}\caption{Grévy's zebras}\label{sub:NScoreExptB}\end{subfigure}
        \caption[\caplbl{NScoreExpt}Name scoring experiment]{\caplbl{NScoreExpt}
            % ---
            Results of the name scoring mechanism experiment.
            There is a clear separation between identification accuracy when the number of exemplars per name is
              $1$ compared to when it is $3$.
            Feature based name scoring (\nsum{}) is slightly more accurate than scoring using the annotation
              based name scoring (\csum{}).
            The number of query /database annotations (\pvar{qsize} / \pvar{dsize}) are shown in the lower left.
            Database size was normalized using confusors.
            %Note that the scores reported here are higher than the baseline for
            %  the same reasons as explained in~\cref{fig:DBSizeExpt}.
            % ---
        }
        \label{fig:NScoreExpt}
    \end{figure}
}



% -------------------------------
% --- K Experiments
% -------------------------------

\begin{comment}
python -m ibeis Chap3.measure kexpt --dbs=GZ_Master1,PZ_Master1
python -m ibeis Chap3.draw kexpt --dbs=GZ_Master1,PZ_Master1 --diskshow
\end{comment}
\newcommand{\KExptA}{
    \begin{figure}[ht!]\centering
        \centering\includegraphics[width=\textwidth]{figuresY/PZ_Master1/kexpt.png}
        \caption[\caplbl{KExptA}The $K$ experiment for plains zebras]{\caplbl{KExptA}
            % ---
            Identification accuracy for plains zebras using different values of $\K$ (the number of nearest
              neighbors assigned to each query feature), different numbers of exemplars (\pvar{dpername}), and
              different database sizes (\pvar{dsize}).
            %Note that the scores reported here are higher than the baseline for
            %  the same reasons as explained in~\cref{fig:DBSizeExpt}.
            % ---
        }
        \label{fig:KExptA}
    \end{figure}
}
\newcommand{\KExptB}{
    \begin{figure}[ht!]\centering
        \centering\includegraphics[width=\textwidth]{figuresY/GZ_Master1/kexpt.png}
        \caption[\caplbl{KExptB}The $K$ experiment for Grévy's zebras]{\caplbl{KExptB}
            % ---
            Identification accuracy for Grévy's zebras using different values of $\K$ (the number of nearest
              neighbors assigned to each query feature), different numbers of exemplars (\pvar{dpername}), and
              different database sizes (\pvar{dsize}).
            %Note that the scores reported here are higher than the baseline for
            %  the same reasons as explained in~\cref{fig:DBSizeExpt}.
            % ---
        }
        \label{fig:KExptB}
    \end{figure}
}


% --- Photobomb

\begin{comment}
python -m ibeis.dev -e draw_cases -a timectrl -t best --filt :fail=True,with_tag=Photobomb,sortdsc=gfscore --db PZ_Master1 \
--qaid=3727 --cmdaug="FailPhotobomb" --hargv=match --render
\end{comment}
\SingleImageCommand{FailPhotobomb}{1}{
    Photobomb failure case
}{
% ---
A photobombing animal in the background of the query annotation cause LNBNN to return the incorrect result (on
  the left) at rank $1$.
The correct match (on the right), has a significant number of matches, but there is a difference of $1$ day
  between the pair.
On the other hand, the annotations in the photobomb pair were taken within minutes of each other and therefore
  have much higher visual similarity.
% ---
}{figuresC/case_FailPhotobomb.png}


% --- Scenery Match

\begin{comment}
python -m ibeis.dev -e draw_cases -a timectrl -t best --filt :fail=True,with_tag=SceneryMatch,sortdsc=gfscore --db GZ_Master1 \
    --qaid 1988 \
    --hargv=match --render  --cmdaug="FailScenery" \
    --cappref="Failure case due to a scenery match. Most scenery match cases have small timedeltas between the images."

# 2811
python -m ibeis.dev -e draw_cases -a timectrl -t best --filt :fail=True,with_tag=SceneryMatch,sortdsc=gfscore --db GZ_Master1 --qaid 1988 --show

python -m ibeis.dev -e draw_cases -a timectrl -t best --filt :fail=True,with_tag=SceneryMatch,sortdsc=gfscore --db GZ_Master1 --qaid 1988 --show
python -m ibeis.dev -e draw_cases -a timectrl -t best:sv_on=False --filt :fail=True,with_tag=SceneryMatch,sortdsc=gfscore --db GZ_Master1 --qaid 1988 --show
python -m ibeis.dev -e draw_cases -a timectrl -t best:sv_on=False,AI=False --filt :fail=True,with_tag=SceneryMatch,sortdsc=gfscore --db GZ_Master1 --qaid 1988 --show
\end{comment}
\SingleImageCommand{FailScenery}{1}{
    Scenery failure case
}{
% ---
The incorrect pair of annotations (on the left) was returned at rank $1$ because of strong matches in the
  background scenery.
The correct pair was returned at rank $2$ and did not produce matches in the front leg due to pose variations.
The annotations in the scenery match pair were taken $8$ seconds appart in the same location causing their
  backgrounds to be near duplicates.
The foregroundness measure was disabled to produce this example, enabling it addresses nearly all scenery match
  cases.
% ---
}{figuresC/case_FailScenery.png}

% --- QUALITY

\begin{comment}
python -m ibeis.dev -e draw_cases -a timectrl -t best --filt :fail=True,with_tag=Quality,sortdsc=gfscore --db GIRM_Master1 --qaid 639 \
    --hargv=match --render --cmdaug="FailQuality" --vert=False
\end{comment}
\SingleImageCommand{FailQuality}{1}{
Quality failure case
}{
% ---
The low resolution of the query annotation and the overall viewpoint difference causes the correct pair of
  annotations (on the right) to be returned at rank $75$.
The incorrect pair of annotation (on the left) did not recieve a particularly high score, but it was returned at
  rank $1$ because there were no feature correspondences established to the correct match.
% ---
}{figuresC/case_FailQuality.png}


% --- OCCLUSION
\begin{comment}
python -m ibeis.dev -e draw_cases -a timectrl -t best --filt :fail=True,with_tag=Occlusion,sortdsc=gfscore --db PZ_Master1 --qaid 3812 \
    --hargv=match --render  --cmdaug="Occlusion" \
    --cappref="Failure case due to occlusion. "
\end{comment}
\SingleImageCommand{FailOcclusion}{1}{
Occlusion failure case
}{
% ---
The plants occluding both the query and database annotations inhibit the creation of feature correspondences,
  causing the correct pair of annotations (on the right) to be returned at rank $2$.
This is exacerbated by pose and viewpoint variations.
The incorrect pair of annotation (on the left) at rank $1$ are relatively distinctive by coincidence.
% ---
}{figuresC/case_Occlusion.png}



% --- VIEWPOINT
\begin{comment}
python -m ibeis.dev -e draw_cases -a timectrl -t best --filt :fail=True,with_tag=Viewpoint,sortdsc=gtscore --db GZ_Master1  --qaid 2787 \
    --hargv=match --render  --cmdaug="FailViewpoint" \
    --overwrite
%--qaid 2660 \
\end{comment}
\SingleImageCommand{FailViewpoint}{1}{
Unaligned failure case
}{
% ---
Due to pose and viewpoint variations, the correctly matching pair of annotations (on the right) is returned at
  rank $2$ while the incorrect pair of annotations (on the left) is returned at rank $1$.
In the correct pair, the features on the front leg are not aligned and failed to match.
In the incorrect pair, the heads of the animals are in a similar pose and thus creating several correspondences
  that are distinctive by coincidence.
% ---
}{figuresC/case_FailViewpoint.png}
