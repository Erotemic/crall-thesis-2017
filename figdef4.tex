
\newcommand{\PairDBStats}{
\begin{table}[b]
    \centering
    \captext[\caplbl{PairDBStats}Database statistics for the pairwise experiment]{
    % ---
    Starting with a database of annotations with name labels, we sample a set of annotation pairs to evaluate our
      pairwise classifiers with.
    % ---
    }
    \label{tbl:PairDBStats}
    \begin{tabular}{lrrrrrr}
    \toprule
               {}   & {Names} & {Annots} & {Positive} & {Negative} & {Incomparable} & {Photobombs} \\
    \midrule
      Plains zebras &            $1202$ &             $5720$ &   $16583$   & $30376$    & $353$  & $286$ \\
     Grévy's zebras &             $771$ &             $2283$ &   $5002$    & $13008$    & $0$    & $76$  \\
    \bottomrule
    \end{tabular}
\end{table}
}


\newcommand{\MatchStateExample}{
\begin{figure}[h] \centering
\begin{subfigure}[h]{0.26\textwidth}\centering\includegraphics[height=160pt]{figures4/classesC.png}\caption{Positive}\label{sub:classesC}\end{subfigure}
\begin{subfigure}[h]{0.31\textwidth}\centering\includegraphics[height=160pt]{figures4/classesA.png}\caption{Negative}\label{sub:classesA}\end{subfigure}
\begin{subfigure}[h]{0.31\textwidth}\centering\includegraphics[height=160pt]{figures4/classesB.png}\caption{Incomparable}\label{sub:classesB}\end{subfigure}
\captext[\caplbl{MatchStateExample}Match-state example]{
% ---
Examples of positive \cref{sub:classesC}, negative  \cref{sub:classesA}, and incomparable \cref{sub:classesB}
pairs of annotations. Local feature correspondences are superimposed over the pairs.
% ---
}
\label{fig:MatchStateExample}
\end{figure}
}


\newcommand{\LeftRightFace}{
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{figures4/custom_match_leftrightface_5245_5161.jpg}
\captext[\caplbl{LeftRightFace}A comparable pair with different viewpoints]{
% ---
Even though this pair has different viewpoints, it is positive and comparable
because we can establish a distinctive correspondence in the face. 
% ---
}
\label{fig:LeftRightFace}
\end{figure}
}


% -------------------
% --- Experiments ---
% -------------------

\begin{comment}
    python -m ibeis Chap4.measure_all --db PZ_PB_RF_TRAIN
    python -m ibeis Chap4.measure_all --db GZ_Master1 && python -m ibeis Chap4.measure_all --db PZ_Master1

    python -m ibeis Chap4.draw_all --db PZ_Master1
    python -m ibeis Chap4.draw_all --db GZ_Master1
\end{comment}

\newcommand{\PositiveHist}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{0.47\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/score_hist_lnbnn.png}\caption{Plains zebras LNBNN}\label{sub:pos_lnbnn_hist_pz}\end{subfigure}
\begin{subfigure}[h]{0.47\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/score_hist_pos_learn(sum,glob).png}\caption{Plains zebras learned}\label{sub:pos_hist_pz}\end{subfigure}
\begin{subfigure}[h]{0.47\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/score_hist_lnbnn.png}\caption{Grévy's zebras LNBNN}\label{sub:pos_lnbnn_hist_gz}\end{subfigure}
\begin{subfigure}[h]{0.47\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/score_hist_pos_learn(sum,glob).png}\caption{Grévy's zebras learned}\label{sub:pos_hist_gz} \end{subfigure}
%~
\captext[\caplbl{PositiveHist}Positive score histogram experiment]{
% ---
This shows positive scores of LNBNN (left) and the pairwise algorithm (right) for pairs of plains (top) and
  Grévy's (bottom) zebras.
The learned probabilities are more separable and more interpretable than LNBNN scores.
%In addition to being more interpretable than LNBNN scores the learned probabilities exhibit better separability.
Note that in this plot, negative refers to annotation pairs with a non-positive match-state label.
% ---
}
\label{fig:PositiveHist}
\end{figure}
}



\newcommand{\PositiveROC}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{0.47\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/roc_match_state.png}\caption{Plains zebras}\end{subfigure}
\begin{subfigure}[h]{0.47\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/roc_match_state.png}\caption{Grévy's zebras}\end{subfigure}
\captext[\caplbl{PositiveROC}Positive match-state ROC experiment]{
% ---
This shows the positive match-state ROC for scores computed by the pairwise classifier and LNBNN.
The pairwise classifier significantly improves the separation of positive and non-positive pairs.
%The scores from the pairwise classifier are better at separating positive and non-positive cases.
%Additionally, operating points exist where the true positive rate is high and
%the false positive rate is near zero.
%can be selected to automatically review a significant number of positive cases
%  while making only a few errors.
% ---
}
\label{fig:PositiveROC}
\end{figure}
}


\newcommand{\ReRank}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/rerank.png}\caption{Plains zebras}\end{subfigure}
\begin{subfigure}[h]{\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/rerank.png}\caption{Grévy's zebras}\end{subfigure}
\captext[\caplbl{ReRank}Re-ranking experiment]{
% ---
Re-ranking the top LNBNN results using the positive probabilities from the match-state classifier improves the
  number of correct matches at rank $1$ for both plains and Grévy's zebras.
% ---
}
\label{fig:ReRank}
\end{figure}
}


\begin{comment}
    python -m ibeis.scripts.thesis ExptChapter4.write_metrics --db GZ_Master1 --task-key=match_state
    python -m ibeis.scripts.thesis ExptChapter4.write_metrics --db PZ_Master1 --task-key=match_state
\end{comment}
\newcommand{\ConfusionMatch}{
\begin{table}[b]
    \centering
    \captext[\caplbl{ConfusionMatch}Match-state experiment confusion matrix]{
    % ---
    This is the multiclass match-state confusion for plains and Grévy's zebras.
    The rows are the real (ground truth) state, and the columns are the predicted states.
    Each pair is classified as positive, negative, or incomparable depending on which state has the maximum
      probability.
    % ---
    }
    \label{tbl:ConfusionMatch}
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/PZ_Master1/confusion_match_state.tex}\caption{Plains zebras match-state confusion matrix}\end{subtable} %
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/GZ_Master1/confusion_match_state.tex}\caption{Grévy's zebras match-state confusion matrix}\end{subtable} %
\end{table}
}


\newcommand{\EvalMetricsMatch}{
\begin{table}[b]
    \captext[\caplbl{EvalMetricsMatch}Match-state experiment evaluation metrics]{
    % ---
    The multiclass match-state evaluation metrics for plains and Grévy's zebras are computed from the confusion
      matrix.
    These metrics demonstrate that our match-state classifiers have strong predictive power.
    % ---
    }
    \label{tbl:EvalMetricsMatch}
    \centering
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/PZ_Master1/eval_metrics_match_state.tex}\caption{Plains zebras match-state metrics}\end{subtable} %
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/GZ_Master1/eval_metrics_match_state.tex}\caption{Grévy's zebras match-state metrics}\end{subtable} %
\end{table}
}

\begin{comment}
    python -m ibeis.scripts.thesis ExptChapter4.write_metrics --db GZ_Master1 --task-key=photobomb_state
    python -m ibeis.scripts.thesis ExptChapter4.write_metrics --db PZ_Master1 --task-key=photobomb_state
\end{comment}
\newcommand{\ConfusionPhotobomb}{
\begin{table}[h]
    \captext[\caplbl{ConfusionPhotobomb}Photobomb-state experiment confusion matrix]{
    % ---
    The columns indicate predicted classes, and the rows indicate real (ground truth) classes.
    The final column indicates the number of examples of each class.
    A pair is classified as a photobomb if its probability is greater than $0.5$.
    % ---
    }
    \label{tbl:ConfusionPhotobomb}
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/PZ_Master1/confusion_photobomb_state.tex}\caption{Plains zebras photobomb confusion matrix}\end{subtable} %
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/GZ_Master1/confusion_photobomb_state.tex}\caption{Grévy's zebras photobomb confusion matrix}\end{subtable} %
\end{table}
}


\newcommand{\EvalMetricsPhotobomb}{
\begin{table}[h]
    \captext[\caplbl{EvalMetricsPhotobomb}Photobomb-state experiment evaluation metrics]{
    % ---
    The photobomb-state evaluation metrics are computed from the confusion matrix.
    A pair is classified as a photobomb if its probability is greater than $0.5$.
    % ---
    }
    \label{tbl:EvalMetricsPhotobomb}
    \centering
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/PZ_Master1/eval_metrics_photobomb_state.tex}\caption{Plains zebras photobomb metrics} \end{subtable} %
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/GZ_Master1/eval_metrics_photobomb_state.tex}\caption{Grévy's zebras photobomb metrics}\end{subtable} %
\end{table}
}


\newcommand{\ConfusionPhotobombII}{
\begin{table}[p]
    \captext[\caplbl{ConfusionPhotobombII}Photobomb-state adjusted confusion matrix]{ 
    % ---
    This shows the confusion matrix after adjusting the probability threshold to maximize the MCC.
    The columns indicate predicted classes, and the rows indicate real (ground truth) classes.
    The final column indicates the number of examples of each class.
    % ---
    }
    \label{tbl:ConfusionPhotobombII}
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/PZ_Master1/confusion2_photobomb_state.tex}\caption{Plains zebras photobomb adjusted confusion matrix}\end{subtable} %
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/GZ_Master1/confusion2_photobomb_state.tex}\caption{Grévy's zebras photobomb adjusted confusion matrix}\end{subtable} %
\end{table}
}


\newcommand{\EvalMetricsPhotobombII}{
\begin{table}[p]
    \captext[\caplbl{EvalMetricsPhotobombII}Photobomb-state adjusted evaluation metrics]{
    % ---
    These evaluation metrics are computed from the confusion matrix after adjusting the probability threshold to
      maximize the MCC.
    % ---
    }
    \label{tbl:EvalMetricsPhotobombII}
    \centering
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/PZ_Master1/eval_metrics2_photobomb_state.tex}\caption{Plains zebras adjusted photobomb metrics} \end{subtable} %
    \begin{subtable}[h]{\textwidth}\centering\input{figures4/GZ_Master1/eval_metrics2_photobomb_state.tex}\caption{Grévy's zebras adjusted photobomb metrics}\end{subtable} %
\end{table}
}



\begin{comment}
    python -m ibeis.scripts.script_vsone report_classifier_importance --db PZ_Master1 \
    --dpath ~/latex/crall-thesis-2017/ --save "figures4/wc_pz_clipwhite2.png" \
    --clipwhite --diskshow

    python -m ibeis.scripts.script_vsone report_classifier_importance --db GZ_Master1 \
    --dpath ~/latex/crall-thesis-2017/ --save "figures4/wc_gz_clipwhite2.png" \
    --clipwhite --diskshow
\end{comment}


\newcommand{\MatchPrune}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{0.49\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/prune.png}\caption{Plains zebras}\end{subfigure}
\begin{subfigure}[h]{0.49\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/prune.png}\caption{Grévy's zebras}\end{subfigure}
\captext[\caplbl{MatchPrune}Pruning feature dimensions for match classification]{
% ---
This shows the effect of pruning the least important feature dimensions on the MCC of the match-state classifier.
We find that a reduced subset of feature dimensions results in a slight increase in classification accuracy over
  the original $131$ features.
However, there is a point at which reducing the number of feature dimensions significantly degrades performance.
% ---
}
\label{fig:MatchPrune}
\end{figure}
}


\newcommand{\ImportantMatchFeatPrune}{
\begin{table}[p]
    \centering
    \captext[\caplbl{ImportantMatchFeatPrune}Important features for match-state prediction]{ 
    % ---
    These are the top $10$ most important feature dimensions for predicting the match-state (positive, negative,
      incomparable) for a pair of annotations, after removing the least important dimensions.
    % ---
    }
    \label{tbl:ImportantMatchFeatPrune}
    \begin{subtable}[h]{1.0\textwidth}
        \centering
        \begin{tabular}{l c}
            \toprule
            Dimension & Importance\\
            \midrule
            \input{figures4/PZ_Master1/pruned_feat_importance_match_state.tex}
            \bottomrule
        \end{tabular}
        \caption{Plains zebras}
    \end{subtable} %
    %~~~~~~~~ 
    \begin{subtable}[h]{1.0\textwidth}
        \centering
        \begin{tabular}{l c}
            \toprule
            Dimension & Importance\\
            \midrule
            \input{figures4/GZ_Master1/pruned_feat_importance_match_state.tex}
            \bottomrule
        \end{tabular}
        \caption{Grévy's zebras}
    \end{subtable} %
\end{table}
}


\newcommand{\ImportantPBFeat}{
    \begin{table}[h]
        \centering
        \captext[\caplbl{ImportantPBFeat}Important features for photobomb-state prediction]{ 
        % ---
        These are the top $10$ most important features for predicting if a pair of annotations has a photobomb.
        Features like speed and GPS delta are important because photobombs are more common in pairs of
          annotations taken at the same time and place.
        Features related to the spatial distribution of the feature correspondences are important because
          photobombing animals often appear off to one side of an annotation.
        %they might preclude a match from occurring,
        %  and because annotations taken
        % ---
        }
        \label{tbl:ImportantPBFeat}
        \begin{subtable}[h]{\textwidth} 
            \centering
            \begin{tabular}{l c}
                \toprule Dimension & Importance\\
                \midrule
                \input{figures4/PZ_Master1/feat_importance_photobomb_state.tex}
                \bottomrule
            \end{tabular}
            \caption{Plains zebras photobomb importance}
        \end{subtable} %
        %~~~~
        \begin{subtable}[h]{\textwidth}
            \centering 
            \begin{tabular}{l c}
                \toprule
                Dimension & Importance\\ 
                \midrule
                \input{figures4/GZ_Master1/feat_importance_photobomb_state.tex}
                \bottomrule
            \end{tabular}
            \caption{Grévy's zebras photobomb importance}
        \end{subtable} %
    \end{table}
}


% ---------------------
% --- Failure Cases ---
% ---------------------



\newcommand{\PairFailPN}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{.65\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_match_nomatch_835_5325.jpg}\end{subfigure}
\begin{subfigure}[h]{.65\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_match_nomatch_1022_7845.jpg}\end{subfigure}
\begin{subfigure}[h]{.65\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_match_state/fail_match_nomatch_1511_2145.jpg}\end{subfigure}
\begin{subfigure}[h]{.65\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_match_state/fail_match_nomatch_1453_2042.jpg}\end{subfigure}
\captext[\caplbl{PairFailPN}Positive pairwise failure case]{
% ---
These pairs are all positive, but the match-state classifier predicts each as negative.
These failures can be attributed to poor image quality, occlusion, and viewpoint variations.
Notice that the positive probability is well above zero in all but one case.
%The pair is positive, but the classifier predicts negative because of occlusion and viewpoint variations.
% ---
}
\label{fig:PairFailPN}
\end{figure}
}



\newcommand{\PairFailNP}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{.7\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_nomatch_match_2157_2240.jpg}\end{subfigure}
\begin{subfigure}[h]{.7\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_nomatch_match_3550_5250.jpg}\end{subfigure}
\begin{subfigure}[h]{.7\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_match_state/fail_nomatch_match_1260_2902.jpg}\end{subfigure}
\begin{subfigure}[h]{.7\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_match_state/fail_nomatch_match_1418_1419.jpg}\end{subfigure}
\captext[\caplbl{PairFailNP}Negative pairwise failure case]{
% ---
These pairs are negative, but the classifier predicts positive.
Notice that the negative probability in each case is not close to zero.
While the classifier can recognize that the matches may be weak, it is not able to explicitly recognize that the
  same region on two animals contains different distinctive patterns.
Photobomb and scenery matches also contribute to negative failure cases.
% ---
}
\label{fig:PairFailNP}
\end{figure}
}


\newcommand{\PairFailIN}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{.6\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_notcomp_nomatch_1806_16228.jpg}\end{subfigure}
\begin{subfigure}[h]{.6\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_notcomp_nomatch_1195_16215.jpg}\end{subfigure}
\begin{subfigure}[h]{.6\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_notcomp_nomatch_2847_16301.jpg}\end{subfigure}
\begin{subfigure}[h]{.6\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_notcomp_match_5245_5676.jpg}\end{subfigure}
\captext[\caplbl{PairFailIN}Incomparable pairwise failure case]{
% ---
These pairs are incomparable, but the classifier predicted either positive or negative.
In part this is due to a small amount of available incomparable training data.
In the top two examples the confidence in the incorrect negative prediction is low.
In the bottom two examples, scenery matches and photobombing animals hinder the classifier's ability to predict
  incomparable.
% ---
}
\label{fig:PairFailIN}
\end{figure}
}

\newcommand{\MatchLabelErrors}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{.7\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_notcomp_match_646_1725.jpg}\end{subfigure}
\begin{subfigure}[h]{.7\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_match_state/fail_match_nomatch_4771_4846.jpg}\end{subfigure}
\begin{subfigure}[h]{.7\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_match_state/fail_nomatch_match_1349_3087.jpg}\end{subfigure}
\begin{subfigure}[h]{.7\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_match_state/fail_nomatch_match_1535_2549.jpg}\end{subfigure}
\captext[\caplbl{MatchLabelErrors}Errors in the match-state ground truth]{
% ---
Ground truth errors in the database are the reason for several match-state failure cases.
In these examples the classifier picks the correct answer even though the ground truth is incorrect.
Note that the probability assigned to the true state of each pair is close to $1.0$.
% ---
}
\label{fig:MatchLabelErrors}
\end{figure}
}


\newcommand{\PBThreshMCC}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{0.47\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/mcc_thresh_photobomb_state.png}\caption{Plains zebras}\end{subfigure}
\begin{subfigure}[h]{0.47\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/mcc_thresh_photobomb_state.png}\caption{Grévy's zebras}\end{subfigure}
\captext[\caplbl{PBThreshMCC}Maximizing the photobomb MCC]{
% ---
Because there are not many labeled photobomb pairs, the probabilities returned by the photobomb-state classifier
  are low.
However, good classification results can be achieved by choosing an operating point that maximizes the MCC.
In each plot the legend indicates the threshold corresponding to the maximum MCC.
% ---
}
\label{fig:PBThreshMCC}
\end{figure}
}


\newcommand{\PBFailures}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{.63\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_photobomb_state/fail_notpb_pb_3844_4160.jpg}\end{subfigure}
\begin{subfigure}[h]{.63\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_photobomb_state/fail_pb_notpb_529_1785.jpg}\end{subfigure}
\begin{subfigure}[h]{.63\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_photobomb_state/fail_pb_notpb_1241_1242.jpg}\end{subfigure}
\begin{subfigure}[h]{.63\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_photobomb_state/fail_pb_notpb_1413_1414.jpg}\end{subfigure}
\captext[\caplbl{PBFailures}Photobomb failure cases]{
% ---
In the top example the classifier incorrectly predicts photobomb due to the alignment of the annotations.
In the next case down, the classifier incorrectly predicts photobomb, but no matches were made between the
  photobombing animals.
The last two cases the classifier incorrectly predicts not photobomb, but the confidence of the prediction is
  low.
% ---
}
\label{fig:PBFailures}
\end{figure}
}



\newcommand{\PBLabelErrors}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{.75\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_photobomb_state/fail_notpb_pb_1063_1072.jpg}\end{subfigure}
\begin{subfigure}[h]{.75\textwidth}\centering\includegraphics[width=\textwidth]{figures4/PZ_Master1/cases_photobomb_state/fail_notpb_pb_3928_4880.jpg}\end{subfigure}
\begin{subfigure}[h]{.75\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_photobomb_state/fail_notpb_pb_1377_1378.jpg}\end{subfigure}
\begin{subfigure}[h]{.75\textwidth}\centering\includegraphics[width=\textwidth]{figures4/GZ_Master1/cases_photobomb_state/fail_notpb_pb_1184_1185.jpg}\end{subfigure}
\captext[\caplbl{PBLabelErrors}Errors in the photobomb-state ground truth]{
% ---
Ground truth errors in the database are the reason for several photobomb-state failure cases.
It is encouraging that the photobomb-state classifier is able to detect errors in the ground truth even given
  only a few training examples.
% ---
}
\label{fig:PBLabelErrors}
\end{figure}
}




\begin{comment}
python -m ibeis.viz.viz_chip HARDCODE_SHOW_PB_PAIR --db PZ_Master1 --has_any=photobomb --index=1 --match \
    --dpath ~/latex/crall-thesis-2017/ --save "figures5/PhotobombExampleC.jpg" \
    --figsize=9,4 --clipwhite --dpi=180 --save

python -m ibeis.viz.viz_chip HARDCODE_SHOW_PB_PAIR --db PZ_Master1 --has_any=photobomb --index=1 \
    --dpath ~/latex/crall-thesis-2017/ --save "figures5/PhotobombExample.jpg" \
    --figsize=9,4 --clipwhite --dpi=300 --saveparts

python -m ibeis.core_annots --test-compute_one_vs_one --show
    
\end{comment}

\newcommand{\PhotobombExample}{
\begin{figure}[h]
\centering
\begin{subfigure}[h]{0.4\textwidth}\centering\includegraphics[height=100pt]{figures5/PhotobombExampleA.jpg}\caption{}\label{sub:PhotobombExampleA}\end{subfigure}
\begin{subfigure}[h]{0.4\textwidth}\centering\includegraphics[height=100pt]{figures5/PhotobombExampleB.jpg}\caption{}\label{sub:PhotobombExampleB}\end{subfigure}
\captext[\caplbl{PhotobombExample}Photobomb example]{
% ---
A secondary animal in an annotation can cause a ``photobomb''.  Notice the
primary animal in~\cref{sub:PhotobombExampleA} appears in the background
of~\cref{sub:PhotobombExampleB}. 
% ---
}
\label{fig:PhotobombExample}
\end{figure}
}
