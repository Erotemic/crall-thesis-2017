\chapter{Graph identification}\label{chap:graphid}
\newcommand{\nT}{N}

%\paragraph{Introduction}
In this chapter we frame the problem of individual animal identification in
  terms of constructing what we refer to as an \emph{decision graph}.
In this graph, each vertex is an annotation, and each edge represents a
  decision made between two annotations.
Edges determine if two annotations are the same (positive) or different
  (negative) individuals or if they cannot be compared (incomparable).
Thus, a correctly constructed decision graph naturally addresses the problem
  of identifying individual animals because each connected component of positive
  edges will be all the annotations from an individual.
Therefore, stated abstractly, goal of graph identification is to determine a
  correct, consistent set of edges in the decision graph.

%\paragraph{Motivation}
To construct the decision graph, we develop a semi-automatic review procedure
  that combines the ranking and verification algorithms presented in
  Chapters~\ref{chap:matching} and \ref{chap:pairclf}.
The ranking algorithm will be used to suggest candidate edges to be placed in
  the graph, and the verification algorithm will be used to automatically review
  as many edges as possible.
%Edges that cannot be automatically reviewed are manual verified.
The key reason for combining these algorithms with a decision graph is to take
  advantage of its connectivity information.
Connectivity not only identifies the individuals, but it can also be used to
  develop graph measures of \emph{redundancy}, \emph{completeness},
  \emph{consistency}, and \emph{convergence}.
By combining these graph measures with the ranking and verification algorithms
  we can prioritize edges for review based on both their pairwise probabilities
  and their ability to affect the consistency of the graph, which in turn allows
  us to:
  %
  \begin{enumin}
    \item increase confidence that the identifications are correct, %
    \item reduce the number of manual reviews,  % 
    \item detect and recover from review errors, and %
    \item determine when identification is complete. %
  \end{enumin}
%\footnote{There are many more properties beyond the ones considered in this
%  these that a graph-based framework can exploit, and we discusses these as
%  challenges for future research at the end of this chapter}

Another nice and important property of the graph identification framework is
  that it is agnostic to the underlying computer vision procedures, which are
  abstracted into into three optional components:
\begin{enumin}
    \item a ranking algorithm used to search for candidate positive edges, %
    \item a verification algorithm used to automatically review edges, and %
    \item a probability algorithm used assign probabilities to edges (note
      this is typically a by-product of the ranking or verification algorithm).
\end{enumin}
In this thesis we ranking algorithm from \Cref{chap:matching}, and the
  verification algorithm from \Cref{chap:pairclf} to define these components
  because these are suitable for identifying textured species.
However, while the review procedure benefits from accurate computer vision
  subroutines it does not depend on them.
This means that existing identification algorithms that only define a subset
  of these procedures (\eg{} contour-based rank-only identification of humpback
  whales and bottlenose dolphins) could be seamlessly incorporated into our
  framework and realize the benefits of graph identification (\eg{} a reduced
  number of manual reviews and error recovery mechanisms).
Furthermore, because pairwise decisions are gathered and maintained by this
  framework, verification algorithms can be retrained and improved, moving
  closer to a fully-automatic algorithm.

This outline of this chapter is as follows:
\Cref{sec:decisiongraph} formalizes the decision graph and summarizes the
  priority based review procedure used to construct it.
\Cref{sec:cand} describes candidate edge generation.
\Cref{sec:decision} discuss how the verification algorithm is used to
  automatically review candidate edges.
\Cref{sec:redun} introduces the redundancy criteria used to eliminate
  candidate edges \Cref{sec:incon} describes the built-in mechanisms for error
  recovery.
\Cref{sec:coverge} discusses the convergence criteria that determines when
  identification is complete.
\Cref{sec:graphexpt} experimentally demonstrates that ability of the graph
  identification algorithm to reduce the number of manual reviews and recover
  from errors.
\Cref{sec:graphconclusion} concludes and summarizes the chapter.


\section{The decision graph}\label{sec:decisiongraph}

\decisiongraph{}

The graph identification algorithm is a review procedure formalized around the
  notion of a \glossterm{decision graph} $G = (V, E)$ whose nodes are
  annotations and whose edges are suggested by a ranking algorithm (LNBNN in our
  case) and decided upon by a combination of the probabilities output by a
  verification algorithm and by manual review.
%It is important to note that alternative ranking and pairwise probability
%  algorithms could be used in place of the two algorithms proposed here.
The edge set $E = E_p \cup E_n \cup E_i$ is composed of three disjoint sets.
Each edge in $E_p$ is \emph{positive}, meaning that it connects two
  annotations determined to be from the same individual.
Each edge in $E_n$ is \emph{negative}, meaning that it connects annotations
  determined to be from different individuals.
Finally, each edge in $E_i$ is \emph{incomparable}, meaning that it connects
  two annotations where it has been determined that there is not enough
  information to tell to tell if they are from the same individual (\eg{} when
  one annotation shows the left side of an animal and another other shows the
  right side).
An example of a decision graph with all three edge types is illustrated in
  \Cref{fig:decisiongraph}.
The goal of graph identification is to construct these edges.

The most important task is to determine the positive edges $E_p$.
This is because each connected component in the subgraph $G_p = (V, E_p)$
  corresponds to a unique individual.
Producing an accurate set of these \glossterm{positive connected components}
  (PCCs) addresses solves the larger problem of animal identification.
However, an algorithm that only determines positive edges is not enough.
This is because the algorithm may have failed to find all positive edges,
  resulting in two unconnected PCCs that should be \emph{merged} into one.

We can gain confidence that all positive edges have been found by using
  negative edges $E_n$, which provide direct evidence that two annotations are
  different individual.
A negative edge between two PCCs means that no other unreviewed edge between
  those PCCs can be positive.
Another important case is when a negative edge is contained within a PCC.
When this happens, the PCC is \emph{inconsistent}, and it implies that it
  contains at least one mistake.
Whenever an inconsistencies is detected, we resolve it using an algorithm we
  will define in \Cref{sec:incon} that restores consistency.

Lastly, incomparable edges, $E_i$, play a minor but necessary role by simply
  signifying that a positive or negative decision cannot be made.
Incomparable edges can exist internally in a PCCs without causing
  inconsistencies or between two PCCS without precluding them from being matched
  at a later point.

%We use the connectivity of these edges to develop graph measures of
%  \emph{redundancy}, \emph{completeness}, \emph{consistency}, and
%  \emph{convergence}.
%We have already introduces the consistency measure, where negative edges
%  internal to PCCs are used to detect inconsistencies.

To reduce the number of potential reviews, notice, that once a group of nodes
  is connected by (a tree of) positive edges, all those nodes in that PCC can be
  inferred to belong to the same individual, and it is not necessary to consider
  any other edge internal to the PCC for review.
Likewise once, a negative edges has been placed between two PCCs, all edges
  between those PCCs can be ignored.
By ignoring these redundant edges we can reduce the number of reviews.
Furthermore, if a negative edge is placed between every pair of PCCs, then all
  individuals must have been discovered and identification has converged.

Unfortunately, there are several issues with these previous observations.
These observations depend on the condition that each edge was correctly
  reviewed.
A small amount of redundant decisions is desirable because it reduces the
  probability that errors have been made and signifies when errors have occurred
  by introducing inconsistencies.
Therefore we will define a redundancy criteria in \Cref{sec:redun} which
  ignores edges within and between PCCs, but only after they meet a minimum
  level of redundancy.
Additionally this deterministic convergence criteria would requires that
  $O(|V|^2)$ edges are reviewed as negative.
We address this concern in \Cref{sec:coverge} using a probabilistic
  convergence criteria.

%Finally, we add a measure of redundancy to both the positive and negative
%  subgraphs to allow the algorithm to detect and recover from mistakes, either
%  in the automatic or manual decision making.

\subsection{The review algorithm}


% Algorithm overview
The review algorithm that produces the edges of a decision graph is outlined
  in Algorithm~\ref{alg:AlgoOverview}.
Akin to a segmentation algorithm~\cite{fulkerson_class_2009} that starts with
  an over-segmentation of an image, the identification graph starts with an
  empty set of edges, $G = (V, \{ \})$, so in essence each annotation starts by
  itself as an individual animal.
Throughout the main algorithm, the graph is maintained in a \emph{consistent}
  state, which means that each PCC has no internal negative edges.

\begin{algorithm}
    \begin{enumln}
    \item Generate and prioritize candidate edges 
    \item Insert candidate edges into a priority queue 
    \item Repeat until the priority queue is empty
    \begin{enumln}
        \item Pop an edge from the priority queue
        \item Make a decision and add the edge to the graph
        \item If the edge causes an inconsistency drop into inconsistency recovery mode
        \item Update the priority queue based on the new edge
        \item If candidate edges require refresh, goto step 1
    \end{enumln}
    \end{enumln}
\caption[Algorithm Overview]{Overview of graph identification}
\label{alg:AlgoOverview}
\end{algorithm}
 
The first step of the algorithm is to generate candidate edges predict
  probability measures (positive, negative, or incomparable) for each candidate
  edge.
In the next step each edge is then entered into a priority queue.
Next, the algorithm enters a loop where the next candidate edge is selected, a
  decision is made about this edges --- either automatically (as much as
  possible) or by the user --- and it is added to the graph.
The algorithm proceeds toward convergence by removing candidate edges from the
  priority queue, either directly from the top of the queue or indirectly by
  eliminating candidate edges that are no longer needed.
A candidate edge is no longer needed when there are sufficient redundancies in
  the edge set within or between its PCCs.
A pair of PCCs is \emph{complete} when there are enough negative edges between
  them.
%A PCC is \emph{complete} when there is a negative edge between it an all other
%  PCCs.

Each new edge addition could trigger two important events:
\begin{enumin}
    \item a \emph{merge} --- addition of a positive edge between different
      PCCs combines them into one PCC, and

    \item an \emph{inconsistency} --- addition of either a negative edge
      within a PCC or a positive edge between PCCs that already have a negative
      edge between them creates an inconsistent PCC.
\end{enumin}
Handling a merge is largely a matter of bookkeeping.
Finding an inconsistency, however, drops the user into inconsistency recovery
  mode where a cycle of hypothesizing one or more edges to fix and manually
  verifying these with the user until consistency is restored.

Finally, the outer loop of the overall algorithm allows the ranking algorithm
  to generate additional candidate edges --- this allows the ranking algorithm
  to take advantage of more subtle matches as the PCCs begin to form
  (\Cref{sec:refresh}).
The priority queue will gradually be emptied as each PCC obtains a
  sufficiently redundant set of positive edges and enough negative edges to be
  complete.
%Ensuring completeness requires examining $O(|V|^2)$ edges, so in practice we
%  develop a learned probabilistic completeness measure.
%If sufficient training data is not available simple heuristics can be used to
%  terminate.
Details of each component in the review algorithm are described in the
  following sections.

% will be emptied when each PCC is sufficiently re
% Obtaining sufficient redundancy and completeness in order to empty the priority queue can,
% Ensuring all PCCs are complete leads to the need to ,
%  so to prevent this we develop a probabilistic measure (\Cref{sec:coverge})
%  that triggers much earlier convergence when positive edges are no longer
%  likely to be found.



\section{Candidate edge generation and priorities}\label{sec:cand}

To generate candidate positive edges the we issue each annotation query to the
  ranking algorithm (the LNBNN from \Cref{chap:matching}), forming edges from
  the resulting ranked lists.
For each candidate edge we use the pairwise algorithm (see
  \Cref{chap:pairclf}) to estimate the positive, negative, and incomparable
  probabilities.
Any edge whose maximum probability is above the threshold for automatic
  decision making is ranked according to this probability.
All other edges are ordered by their positive probability.
This ensures automatic decision making is first, followed by an ordering of
  the edges needed for manual review that are most likely to be positive and
  therefore add the most to the graph.

\section{Making decisions}\label{sec:decision}

%Threshold or manual review.
%Briefly discuss importance of minimizing manual review.
%Very short here.

For each proposed new edge, its positive, negative, and incomparable state
  probabilities are produced by the pairwise algorithm.
Each of these three states have an associated hyperparameter threshold, and if
  a single probability is greater than its threshold that edge is automatically
  added to the edge set corresponding to the predicted state.
Otherwise, the edge is sent for manual labeling and then added to the
  appropriate edge set.
% After each decision we determine the effects of the new review and update
%   candidate edge priorities as we will discuss in\cref{sec:redun}.
% However, if the edge causes an inconsistency we drop into inconsistency mode.
% Inconsistency recover will be discussed in \cref{sec:incon}.

\section{Positive and negative redundancy}\label{sec:redun}
%One paragraph on notion.
%One paragraph on algorithm.
%One paragraph on book-keeping and elimination from priority queue.

Before describing the removal of edges from the priority queue and the
detection and correction of inconsistencies, we formalize the notion of
redundancy that is the basis for both of these.
% Before we remove edges from the priority queue, we enforce a minimum level of redundancy.
%This $k$-redundancy criteria is tied to the number of mistakes that must be
%  made in order for part of the graph to incorrectly appear consistent or
%  complete.
%For a PCC (or pair of PCCs) to simultaneously contain a mistake and be
%  $k$-redundant then at least $k$ consistent mistakes must be made.
We define both a positive and a negative redundancy criteria:
\begin{enumerate}[label={(\arabic*)},noitemsep,nolistsep]

    \item $k$-positive-redundancy --- % 
        A PCC is strictly-positive-redundant if its positive subgraph is
          $k$-edge-connected (contains no cut-sets involving fewer than $k$
          positive edges\cite{Tarjan}).
        If the PCC has $k$ or fewer nodes it can be considered
          loosely-positive-redundant if its positive subgraph is complete (all
          possible edges are reviewed).
        Unless otherwise specified, we use positive-redundancy to refer to
          loose-positive-redundancy.

    \item $k$-negative-redundancy --- % 
        A pair of PCCs $C$ and $D$ is strictly-negative-redundant if there are
          $k$ negative edges between $C$ and $D$.
        If either PCC has fewer than $k$ nodes, we consider the pair to be
          loosely-negative-redundant if there are at least $\mathop{max}(|C|,
          |D|)$ negative edges between them.
        Unless otherwise specified, we use negative-redundancy to refer to the
          loose version.
    %which can be determined in $O(n_1 n_2)$ time.
    %(by looping over adjacency sets of nodes
    %in $C$ and performing set intersection with nodes in $D$ to get the edges
    %between $C$ and $D$).

    %$k$-negative-redundant if there are $k$ negative edges between them.
\end{enumerate}
To understand these criteria better, consider what it means for an incorrect
  PCC that has been determined to be $k$-positive-redundant to have an
  undiscovered error.
The error means that the PCC really should be split into (at least) two
  separate PCCs.
Suppose these PCCs correspond to animals $C$ and $D$.
If the combined PCC is $k$-positive-redundant then are $k$ separate
  undiscovered mistakes connecting $C$ and $D$, and no negative edges.
This may be plausible if $C$ were identical twins, but these tend not to occur
  for species where the distinguishing markings (\eg{} hip and shoulder of
  zebras) are mostly random.
  %\footnote{The exception to this is near identical images --- taken at most a few seconds apart --- and we implement a simple heuristic to eliminate these redundancies.}
Note that $k$ can be different for positive and negative redundancy, but in
  our current implementation we use $k=2$ for both positive and negative
  redundancy.

For positive-redundancy, determining that the minimal size cut-set in a PCC is
  at least $k$ can be done in linear time (in the number of component vertices)
  for $k \leq 3$~\cite{wang_simple_2015}.
Determining if two components are $k$-negative-redundant is a simple matter of
  bookkeeping.


  \kredun{}
% -positive-redundant 
% can be done in linear time in the size of the PCC 
% The $k$-positive-redundancy-update procedure procedure finds all
%  $k$-edge-connected components within a PCC $C$ and removes edges internal to
%  those components from the priority queue.
% When $k\leq3$ this can be done in $O(n)$.
%
% The $k$-negative-redundancy-update procedure determines if two PCCs $C$ and
%  $D$ with sizes $n_1$ and $n_2$ are $k$-negative-redundant in $O(n_1 n_2)$ time.
  % %using adjacency lists and set intersections.
% If $C$ and $D$ have enough negative edges between them, all other edges
%  between $C$ and $D$ are removed from the priority queue.

%Note, that some PCCs (or pairs) do not have sufficient positive edges that
%  would make them redundant.
%This could be because the PCCs are too small or because other edges are marked
%  as incomparable.
%For the purposes of convergence such cases are marked as redundant.

When a positive edge is added within a single PCC, we check for
  positive-redundancy.
If this passes, all remaining internal edges for that PCC may be  removed from
  the priority queue.
When a negative edge is added between a pair of PCCs, we run the
  negative-redundancy check on the pair, and if this passes, all remaining edges
  between the PCCs may be removed from the priority queue.
When a positive edge is added between a pair of PCCs, the two PCCs are merged
  into a single new PCC $C'$, and the above negative-redundancy check must be
  run between $C'$ and all other PCCs having a negative edge connecting to $C'$.
It can be shown that if the graph is in a consistent state, that these are the
  only updates required.

\section{Recovering from inconsistencies}\label{sec:incon}
Whenever a decision is made that either adds a negative edge within a PCC or
  adds a positive between two PCCs with at least one negative edge between them,
  the graph becomes inconsistent.
In both of these cases we add the edge and create the result that there is a
  single PCC $C$ with internal negative edges.
An example of an inconsistent PCC is illustrated in \cref{fig:inconpcc}.

The goal of inconsistency recovery mode is to change the labels of edges in
  order to make $C$ consistent.
An inconsistency implies that a mistake was made, but does not necessarily
  determine which edge contains the mistake.
Therefore, we develop an algorithm to hypothesize the edge(s) most likely to
  contain the mistake(s) using a minimum cut.
We describe the case where $C$ only contains one negative edge, but the
  general case replaces min-cut with
  multicut~\cite{vazirani_approximation_2013}.

\inconpcc{}

The procedure alternates between steps of generating ``mistake hypothesis''
  edges, and presenting these to the user for review.
The ``hypothesis generation algorithm'' returns a set of negative edges or a
  set of positive edges, which if the re-labeled as positive or negative
  respectively would cause $C$ to become consistent.
The algorithm starts by creating an instance of the min-cut using the subgraph
  of $C$ containing only positive edges and the endpoints of the negative edge
  as the terminal nodes.
The weight for each edge is its initial priority plus the number of times that
  edge was manually reviewed.
%The weight of the edges is the initial priority for automatically decided edges and a constant, slightly below 1 for manually-decided edges.
The minimum cut returns a set of edges that disconnects the terminal nodes.
We compare the total weight of cut positive edges with the weight of the
  terminal negative edge (weighted using the same scheme).
If the positive weight is smaller the algorithm suggests that the cut positive
  edges should be relabeled as negative.
Otherwise, it suggests that the negative edge should become positive.

The user reviews each edge and the algorithm changes the label of the edge
  until the reviewer disagrees with the algorithm's suggestion or the review set
  is empty.
%\footnote{For our purposes here an \emph{incomparable} label by the user is counted as consistent.} 
If consistency has not been restored, the algorithm must be repeated.
%In the latter case, consistency has been restored.
%In the former case, a new inconsistency has been created and the algorithm
%  must be repeated.
When this happens, the weights of the newly reviewed edges are increased by
  $1$ in order to force the algorithm to look elsewhere for a cut.
This repeats until all inconsistencies are eliminated.
If this results in splitting one PCC into two or more, then the
  positive-redundancy and negative-redundancy tests must be repeated,
  potentially re-adding edges to the priority queue.

%As a final note, in order to ensure that this algorithm detects errors, the
%  candidate edges must contain edges that are likely to cause inconsistencies.
%Therefore, the initial set of candidate edges (described in \cref{sec:cand})
%  is always augmented with a edges that would make each non-positive-redundant PCC
%  positive-redundant.

%must ensure that inconsistencies can occur and errors can be found, 

%To ensure that the As a final note on redundancy, we elaborate on the additional edges.
  

% This algorithm generates hypothesis edges for a user to review until all
%   inconsistencies are eliminated.
% If this results in splitting $C$ into multiple PCCs, then previous implicit
%   reviews within or incident to this subgraph may no longer be valid.
% Therefore we recompute $k$-positive-redundancy within each new PCC, implicitly
%   reviewing edges where the criteria is satisfied and re-adding edges where it
%  is no longer valid.
% A similar process happens for $k$-negative-redundancy between each pair of new
%   PCCs as well as between each new PCC and all other PCCs previously
%   $k$-negative-redundant with $C$.


%multicut~\cite{vazirani_approximation_2013} 

%When $k=2$ for $k$-positive-redundancy, it is only possible for a single
%  negative edge to exist within a PCC. In this case 

%the algorithm creates 

%The algorithm starts by creating an instance of the
%  multicut~\cite{vazirani_approximation_2013} using the subgraph of $C$
%  containing only positive edges.
%Each edge is weighted by its assigned positive pairwise probability plus the
%  number of times that edge was manually reviewed.
%The terminal pairs are the negative edges.
%A feasible multicut returns a subset of  that disconnects all terminal pairs.
%Multicut is NP-hard, but it can be approximated by taking the union of
%  min-cuts between each terminal pair.
%To transform the multicut into a mistake hypothesis, we compare the total
%  weight of cut positive edges with the total weight of the terminal negative
%  edges (weighted using the same scheme).
%If positive weight is smaller we suggest that the cut positive edges should be
%  relabeled as negative.
%Otherwise, we suggest the negative edges should be relabeled as positive.

%Inconsistency recovery proceeds as follows.
%Generate a mistake hypothesis, and order the edges by positive probability.
%Present each edge hypothesis to the user in order.
%If the user agrees with the hypothesis, then change the edge label, increment
%  its review count, and continue.
%If the user disagrees, then generate a new hypothesis (using new weights and
%  labels) and restart.
%It can be shown that this process is guaranteed to converge on a consistent
%  graph state.
%Once $C$ is consistent, re-add it to $G$ and return to the main loop.

%Fixing inconsistencies can result in splitting $C$ into multiple PCCs and
%  invaliding implicit reviews inferred from $k$-redundancy either within or
%  incident to this subgraph.
%Therefore we recompute $k$-positive-redundancy within each new PCC, implicitly
%  reviewing edges where the criteria is satisfied and re-adding edges where it
%  is no longer valid.
%A similar process happens for $k$-negative-redundancy between each pair of new
%  PCCs as well as between each new PCC and all other PCCs previously
%  $k$-negative-redundant with $C$.


\section{Refreshing candidate edges}\label{sec:refresh}

As the review process executes we want to continue to review positive matches
  as long as we are discovering them.
However, at some point the candidate edges may no longer contain positive
  results, but undiscovered positive matches may still exist.
This is because LNBNN, working initially with each annotation having a
  separate label, can miss more subtle but correct matches, especially when
  there are several annotations for an animal and subtle viewpoints.
As the labeling improves, so does the reliability of the LNBNN.
Therefore, we define a refresh criteria to determine when we should recompute
  candidate edges.

The goal is to refresh if there has been a significant number of positive
  reviews, but new results are consistently negative.
If we have not found any positive edges then we do not want to refresh.
We keep track of the fraction of positive review decisions as a moving average
  of manual decisions.
We also maintain the total number of positive reviews made since the last
  candidate edge generation.
Thus the candidate edges are refreshed whenever the number of positive reviews
  is above a threshold and the positive review fraction is below a threshold

As the last outer iteration of the overall algorithm before convergence,
  triggered when the LNBNN ranking algorithm fails to produce positive edges,
  candidate edges between untested pairs of annotations are added within PCCs
  that are not positive-redundant and between PCCs that are not
  negative-redundant.
This is because the ranking algorithm itself is imperfect and the missed
  matches tend to affect small PCCs disproportionately, which are the last to
  satisfy redundancy tests.


\section{Probabilistic convergence}\label{sec:coverge}

The goal of probabilistic convergence is to determine if a PCC $C$ is
  negative-redundant with all other components with high probability.
When all components are positive-redundant and satisfy this, then all edges
  will be removed from the priority queue and the algorithm will converge.
We consider the probability $\Pr(E_c \given \nT_C)$ that an undiscovered
  positive edge exists ($E_C$) given $C$'s existing set of outgoing negative
  edges ($\nT_C$).
Under mild conditions % if we assume that $\Pr(E_c \given \nT_C) < .5$, 
we can show that the probability $\Pr(\nT_C \given E_C)$ of observing the
  negative edges bounds this p given that an undiscovered match exists can be
  used as a surrogate.
We can learn this probability offline by measuring the frequency that correct
  results are at a given rank in a PCC's ranked list (constructed by aggregating
  the ranked lists of all annotations in the PCC).


\subsection{Convergence as a Poisson process}

To determine when to stop we consider the question:
``How many unreviewed edges in the graph are likely to be positive?''.
We can obtain an upper bound on this number by modeling the probability that a
  new edge will be positive as a Poisson processes.

We consider a window of previous reviews between annotations where (at the
  time) the annotations belonged to different names.
A fraction of these reviews will be labeled as positive, resulting in a merge.
This fraction $\mu$ is the mean of a Poisson distribution.
Multiplying $\mu$ by a positive integer $k$ estimates the expected number of
  positive matches we will observe in next $k$ reviews between different PCCs.
If the current number of PCCs is $N$, and we know $M$ pairs of PCCs are
  negative-redundant, then the number of edges to complete the negative labeling
  is $k=\binom{N}{2} - M$.
Thus, at any point we can estimate the number of undiscovered positive reviews
  as $k\mu$.

In practice, this number will be much greater than the actual number of
  remaining merges because our event is not a strict Poisson process.
This is because the probability of observing a positive edge is not constant
  over time, it depends on the previously observed positive edges.
However, because each positive review removes other positive reviews remaining
  in the graph, and because we prioritize by positive probability, the
  probability of observing a positive edge will decrease with each new review.
This is what allows us to use the Poisson process as an upper bound.
%Re-estimating the $k\mu$ at each time-step should



%\begin{comment}
%To predict $\Pr(\nT_C \given E_C)$ we first combine the LNBNN scores from each
%  annotation in $C$ into a single ranked list for the entire PCC.
%This can be done by sorting the maximum LNBNN score to each database PCC.
%Let $R_C$ denote the ranks of every PCC marked as negative with $C$.
%In an offline step we learn a probability mass function $\phi$ that predicts
%  the probability that a correct match appears at a given rank for the PCC $C$.
%The predicted probability is %
%$\Pr(\nT_C \given E_C) = 1 - \sum_{r \in R_C} \phi(r)$.

%To learn $\phi$, we measure the probability that a correct match appears at a
%  given rank, given a correct match exists.
%To do this initialize an accumulator.
%For each $C$ in the training set, divide it into a query $C_q$ and target
%  $C_t$.
%The target and the rest of the PCCs in the training set become database PCCs.
%Use LNBNN to score each annotation in $C_q$ against the database PCCs.
%Determine the best rank that $C_t$ appears in each ranked list, and increment
%  the corresponding index in the accumulator.
%Repeat this process for all PCCs in the training set and for multiple
%  partitions of each PCC.
%Normalizing and smoothing the accumulation array results in the PMF $\phi$.
%%Smoothing the accumulation array results in the PMF $\phi$.
%%Estimate the PMF $\phi$ by applying kernel density estimation to the
%%  accumulation array.
%In order to prevent marginalization across important attributes (such as the
%  number of exemplars in a PCC), construct multiple PMFs for different numbers
%  of exemplars in a query.
%\begin{comment}


\subsection{Exemplar selection}\label{sec:exempselect}
    To scale one-vs-many matching to larger databases and to allow the LNBNN
    mechanism to find appropriate normalizers we restrict the number of
    examples of each individual in the database to a set of exemplars.

    Exemplars that represent a wide range of viewpoints and poses are
      automatically chosen using a modified version of the technique presented
      in~\cite{oddone_mobile_2016}.
    The idea is to treat exemplar selection as a maximum weight set cover
      problem.
    For each individual, the input is a set of annotations.
    A similarity score is computed between pairs of annotations.
    To compute covering sets we first choose a threshold, each annotation is
      assigned a covering set as itself and the other annotations it matches
      with a similarity score above that threshold.
    The maximum number of exemplars is restricted by setting a maximum weight.
    Searching for the optimal set cover is NP-hard, therefore we use the
      greedy %
    $(1 - \frac{1}{e})$-approximation algorithm~\cite{michael_guide_1979}.
    The algorithm is run for several iterations in order to find a good
      threshold that minimizes the difference between the weight of the set
      cover and the maximum weight limit.

    The similarity score can be computed using the one-vs-many algorithm, but
      in our work we develop a probabilistic one-vs-one algorithm that better
      suits this purpose.

\section{Experiments}\label{sec:graphexpt}
    In this section we design an experiment to measure the impact of graph
      identification on the number of manual reviews required to complete
      identification as well as the accuracy of those identifications.
    Our experiments simulates the semi-automatic identification process from a
      user's perspective.
    We consider three algorithms:
    (1) our graph identification algorithm,
    (2) a baseline ranking-based protocol, and
    (3) an intermediate ranking protocol that combines the ranking algorithm
      with pairwise classifier.
    To simulate our algorithms, we model noisy user response using
      ground-truth data.
    The simulated user returns the ground-truth classification 98\% of the
    time, making errors 2\% of the time uniformly at random.

    The protocol for the graph identification algorithm is defined in
      \Cref{sec:s5}.
    The pairwise classifier, corresponding thresholds, and termination
      criteria are learned on a disjoint training set.
    Because our algorithm is able to handle errors, we set our automatic
      classification thresholds to achieve a false positive rate of $.1\%$ 
    on a validation set.
    We disable automatic review for incomparable cases due to the small number
      of labeled training examples.

    The baseline algorithm captures the effect of using a purely rank-based
      approach for animal identification.
    We first run the ranking algorithm and add the top $5$ results from each
      query to a list sorted by the LNBNN score.
    The user reviews each result in the list sequentially, without regard to
      the underlying graph structure.
    Once, new matches are consistently negative (using the approach from
      ~\cref{sub:refresh}), we regenerate a new ranked list and iterate.
    We terminate after two rounds of ranking and review.

    The intermediate protocol will demonstrate the effect of augmenting the
      baseline algorithm with our pairwise classifier.
    The procedure is the exactly the same as the baseline algorithm, except
      that any item with a predicted probability above a threshold is
      automatically reviewed.
    Because this approach has no mechanism for error recovery, we choose
      conservative classification thresholds that achieve a $0\%$ false 
    positive rate on a validation dataset.

    In all tests we record two measurements after each review pertaining to
      accuracy and error.
    (1) The accuracy measurement is the number of merges remaining before all
      individuals have been identified.
    This is the number of edges in a spanning forest of the ground-truth
      positive subgraph minus same measurement but applied to the subgraph of
      all correctly predicted positive edges.
    (2) The error measurement is the total number of edges with a predicted
      state that differs from its ground-truth state.

    Results of this test for the graph, intermediate and baseline algorithms
      are illustrated in \cref{fig:ETE} for each dataset.
    These results demonstrate that the algorithms using the pairwise
      classifier significantly improves the rate at which annotations from the
      same individual are merged.
    However, the graph algorithm better suited to take advantage of the
      pairwise classifier because it can afford to a make initial mistakes and
      expect to recover from them later.
    The baseline and intermediate algorithm have no mechanism for error
      recovery, and thus their error steadily increases over time.
    In these cases a significant number of individuals will be misidentified.
    These results also demonstrate that the graph algorithm is able to recover
      from many of these errors.
    We note that the remaining errors might be resolved if more images of
      individuals involved in those errors are added to the system.

 
\section{Conclusion and summary of graph identification}\label{sec:graphconclusion}

A nice and important property of the graph identification framework is
  that it is agnostic to the underlying procedures used to generate and review
  candidate edges to be placed in the decision graph.
Throughout this chapter we will have used the ranking algorithm from
  \Cref{chap:matching}, and the semi-automatic verification algorithm from
  \Cref{chap:pairclf}, which work well for distinctively textured species like
  zebras, giraffes, jaguars, and lionfish.
However, the benefits of graph identification algorithm could be realized for
  less textured species such as humpbacks whales or bottlenose dolphins by
  simply using existing contour-based ranking algorithms and a manual reviewer.

%The framework requires two external components:
%\begin{enumin}
%    \item a ranking algorithm to search for candidate edges, and
%    \item a verification algorithm (either manual or automatic) that can
%      decide if a pair of annotation is positive, negative, or incomparable.
%  \end{enumin}
The verification algorithm (which can be a manual reviewer) is what determines
  if the graph identification algorithm is manual, semi-automatic, or
  fully-automatic.
In our experiments we use the ranking algorithm from \Cref{chap:matching}, and
  the verification algorithm from \Cref{chap:pairclf} to construct these
  components, which work well for
  
%These algorithms could easily be swapped out for other algorithms tuned
%  towards specific species (\eg{} contour-based ranking algorithms for marine
%  species).
%(or any object that can be visually identified).
Furthermore, as more pairwise training data is gathered and maintained using
  this framework, more sophisticated pairwise classifiers trained using deep
  learning could be applied, perhaps removing the manual component completely
  and resulting in a fully automatic identification algorithm.

Because of this flexibility the graph identification framework generalizes
  beyond animal identification and could be applied to any instance recognition
  problem using algorithms tuned for those tasks under the condition that one
  annotation corresponds to one individual object (note the photobomb classifier
  can be used to relax this constraint).


