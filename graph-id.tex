\chapter{Graph identification}\label{chap:graphid}
\newcommand{\nT}{N}

In this chapter we frame the problem of animal identification in terms of constructing a %
\glossterm{decision graph}.
In this graph, each vertex is an annotation, and each edge represents a decision made between two annotations.
Edges determine if two annotations are the same (positive) or different (negative) individuals or if they cannot
  be compared (incomparable).
Thus, a correctly constructed decision graph naturally addresses the problem of identifying individual animals
  because each connected component of positive edges will be all the annotations from an individual.
Therefore, stated abstractly, goal of graph identification is to determine a correct, consistent set of edges in
  the decision graph.

To construct the decision graph, we develop a semi-automatic review procedure that combines the ranking and
verification algorithms presented in Chapters~\ref{chap:ranking} and \ref{chap:pairclf}. The ranking algorithm will
be used to suggest candidate edges to be placed in the graph, and the verification algorithm will be used to
automatically review as many edges as possible.  The key reason for combining these algorithms with a decision
graph is to take advantage of its connectivity information.  Connectivity not only identifies the individuals, but
it can also be used to develop graph measures of \emph{redundancy}, \emph{completeness}, \emph{consistency}, and
\emph{convergence}.  By combining these graph measures with the ranking and verification algorithms we can
prioritize edges for review based on both their pairwise probabilities and their ability to affect the consistency
of the graph, which in turn allows us to:
\begin{enumin}
\item increase confidence that the identifications are correct, %
\item reduce the number of manual reviews,  % 
\item detect and recover from review errors, and %
\item determine when identification is complete. %
\end{enumin}

Another important property of the graph identification framework is that it is agnostic to the underlying computer
vision procedures, which are abstracted into into three components:
\begin{enumin}
\item a ranking algorithm used to search for candidate positive edges, %
\item a verification algorithm used to automatically review edges, and %
\item a probability algorithm used assign probabilities to edges (note this is typically a by-product of the
ranking or verification algorithm).
\end{enumin}
In this thesis we use ranking algorithm from \cref{chap:ranking}, and the verification algorithm from
\cref{chap:pairclf} to define these components because these are suitable for identifying textured species.
However, while graph identification benefits from accurate computer vision subroutines, it can stand alone without
them.  This means that existing identification algorithms that only define a subset of these procedures (\eg{}
contour-based rank-only identification of humpback whales and bottlenose dolphins) could be seamlessly incorporated
into our framework and realize the benefits of graph identification (\eg{} a reduced number of manual reviews and
error recovery mechanisms).  Furthermore, because pairwise decisions are gathered and maintained by this framework,
verification algorithms can be retrained and improved, moving closer to a fully-automatic algorithm.


The first section (\Cref{sec:decisiongraph}) of this chapter formalizes the decision graph and summarizes the
  priority based review procedure used to construct it.
This provides a brief overview of each component of the processes, and then details are described in subsequent
  sections.
Then, \Cref{sec:rename} describes how existing database can be ported into this framework without extensive
  re-review.
\Cref{sec:graphexpt} experimentally demonstrates that ability of the graph identification algorithm to reduce the
  number of manual reviews and recover from errors.
\Cref{sec:graphconclusion} concludes and summarizes the chapter.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The decision graph}\label{sec:decisiongraph}

\decisiongraph{}

The graph identification algorithm is a review procedure formalized around the notion of a \glossterm{decision
graph} $G = (V, E)$ whose nodes are annotations and whose edges are suggested by a ranking algorithm (LNBNN in our
case) and decided upon by a combination of the probabilities output by a verification algorithm and by manual
review.  The edge set $E = E_p \cup E_n \cup E_i$ is composed of three disjoint sets. Each edge in $E_p$ is
\emph{positive}, meaning that it connects two annotations determined to be from the same individual. Each edge in
$E_n$ is \emph{negative}, meaning that it connects annotations determined to be from different individuals.
Finally, each edge in $E_i$ is \emph{incomparable}, meaning that it connects two annotations where it has been
determined that there is not enough information to tell to tell if they are from the same individual (\eg{} when
one annotation shows the left side of an animal and another other shows the right side).  An example of a decision
graph with all three edge types is illustrated in \cref{fig:decisiongraph}. The goal of graph identification is to
construct these edges.

The most important task is to determine the positive edges $E_p$.  This is because each connected component in the
subgraph $G_p = (V, E_p)$ corresponds to a unique individual.  Producing an accurate set of these
\glossterm{positive connected components} (PCCs) addresses solves the larger problem of animal identification.
However, an algorithm that only determines positive edges is not enough.  This is because the algorithm may have
failed to find all positive edges, resulting in two unconnected PCCs that should be \emph{merged} into one.

We can gain confidence that all positive edges have been found by using negative edges $E_n$, which provide
  direct evidence that two annotations are different individual.
A negative edge between two PCCs means that no other unreviewed edge between those PCCs can be positive.
Another important case is when a negative edge is contained within a PCC.
When this happens, the PCC is \emph{inconsistent}, and it implies that it contains at least one mistake.
Whenever an inconsistency is detected, we resolve it using an algorithm we will define in~\cref{sec:incon}.

Lastly, incomparable edges, $E_i$, play a minor but necessary role by simply signifying that a positive or negative
decision cannot be made.  Incomparable edges can exist internally in a PCCs without causing inconsistencies or
between two PCCS without precluding them from being matched at a later point.

To reduce the number of potential reviews, notice, that once a group of nodes is connected by (a tree of)
  positive edges, all those nodes in that PCC can be inferred to belong to the same individual, and it is not
  necessary to consider any other edge internal to the PCC for review.
Likewise once, a negative edges has been placed between two PCCs, all edges between those PCCs can be ignored.
By ignoring these redundant edges we can reduce the number of reviews.
Furthermore, if a negative edge is placed between every pair of PCCs, then all individuals must have been
  discovered and identification has converged.
Unfortunately, there are several issues with these previous observations.
These observations depend on the condition that each edge was correctly reviewed.
A small amount of redundant decisions is desirable because it reduces the probability that errors have been made
  and signifies when errors have occurred by introducing inconsistencies.
Therefore we will define a redundancy criteria in~\cref{sec:redun} which ignores edges within and between PCCs,
  but only after they meet a minimum level of redundancy.
Additionally this deterministic convergence criteria would requires that $O(|V|^2)$ edges are reviewed as
  negative.
We address this concern in~\cref{sec:converge} using a probabilistic termination criteria.

\subsection{The review algorithm}\label{sub:graphalgo}


% Algorithm overview
The review algorithm that produces the edges of a decision graph is outlined in Algorithm~\ref{alg:AlgoOverview}.
Akin to a segmentation algorithm~\cite{fulkerson_class_2009} that starts with an over-segmentation of an image,
  the identification graph starts with an empty set of edges, $G = (V, \{ \})$, so in essence each annotation
  starts by itself as an individual animal.
Throughout the main algorithm, the graph is maintained in a \emph{consistent} state, which means that each PCC
  has no internal negative edges.

\begin{algorithm}
    \begin{enumln}
    \item Generate and prioritize candidate edges 
    \item Insert candidate edges into a priority queue 
    \item Repeat until the priority queue is empty
    \begin{enumln}
        \item Pop an edge from the priority queue
        \item Make a decision and add the edge to the graph
        \item If the edge causes an inconsistency drop into inconsistency recovery mode
        \item Update the priority queue based on the new edge
        \item If candidate edges require refresh, break
    \end{enumln}
    \item If the graph has not converged, repeat. Otherwise, terminate.
    \end{enumln}
\caption[Algorithm Overview]{Overview of the graph identification review procedure}
\label{alg:AlgoOverview}
\end{algorithm}

The first step of the algorithm is to generate candidate edges predict probability measures (positive, negative,
  or incomparable) for each candidate edge.
In the next step each edge is then entered into a priority queue.
Next, the algorithm enters a loop where the next candidate edge is selected, a decision is made about this edges
  --- either automatically (as much as possible) or by the user --- and it is added to the graph.
The algorithm proceeds toward convergence by removing candidate edges from the priority queue, either directly
  from the top of the queue or indirectly by eliminating candidate edges that are no longer needed.
A candidate edge is no longer needed when there are sufficient redundancies in the edge set within or between its
  PCCs.
A pair of PCCs is \emph{complete} when there are enough negative edges between them.

Each new edge addition could trigger two important events:
\begin{enumin}
    \item a \emph{merge} --- addition of a positive edge between different
      PCCs combines them into one PCC, and

    \item an \emph{inconsistency} --- addition of either a negative edge within a PCC or a positive edge between
      PCCs that already have a negative edge between them creates an inconsistent PCC.
\end{enumin}
Handling a merge is largely a matter of bookkeeping and can be done efficiently using a data structure that can
  dynamically maintain connected components~\cite{jacob_holm_poly_logarithmic_1998}.
Finding an inconsistency, however, drops the user into inconsistency recovery mode which alternates between
  hypothesizing one or more edges to fix and manually verifying these edges with the user until consistency is
  restored.

Finally, the outer loop of the overall algorithm allows the ranking algorithm to generate additional candidate
  edges --- this allows the ranking algorithm to take advantage of more subtle matches as the PCCs begin to form.
The priority queue will gradually be emptied as each PCC obtains a sufficiently redundant set of positive edges
  and enough negative edges to be complete.
%Ensuring completeness requires examining $O(|V|^2)$ edges, so in practice we
%  develop a learned probabilistic completeness measure.
%If sufficient training data is not available simple heuristics can be used to
%  terminate.

Details of each step in the review algorithm are described in the following sections.
First we describe the redundancy criteria in~\cref{sec:redun} and inconsistency recovery in~\cref{sec:incon}.
These will serve to inform the sections that define candidate edge generation, in~\cref{sec:cand}, decision
  making in~\cref{sec:decision}, and the refresh and termination criteria in~\cref{sec:converge}.

% will be emptied when each PCC is sufficiently re
% Obtaining sufficient redundancy and completeness in order to empty the priority queue can,
% Ensuring all PCCs are complete leads to the need to ,
%  so to prevent this we develop a probabilistic measure (\cref{sec:converge})
%  that triggers much earlier convergence when positive edges are no longer
%  likely to be found.

\section{Positive and negative redundancy}\label{sec:redun}
%One paragraph on notion.
%One paragraph on algorithm.
%One paragraph on book-keeping and elimination from priority queue.

In this section we define a criteria that
(1) increases our confidence that PCCs are correct by enforcing a minimum level of redundancy and
(2) prevents edges that exceed this redundancy from being reviewed.
At a minimum each PCC must be a tree of positive edges, but when errors can occur, it's difficult to be confident
  that all nodes in the PCC are really the same individual.
By adding a redundant edge we either increase the confidence that other edges are correct or detect an
  inconsistency which can be resolved with the algorithm in ~\cref{sec:incon}.
However, the gains in confidence from adding each additional edge are diminishing.
Therefore, it is desirable to achieve a minimum level of redundancy, but once this has been achieved we should
  prevent additional redundant edges from being reviewed.
We formalize this minimum level of redundancy in two forms.
The first is for positive edges within PCCs and the second is for negative edges between PCCs.
\begin{enumln}

    \item positive-redundancy --- % 
        A PCC is $k$-positive-redundant if its positive subgraph is $k$-edge-connected (contains no cut-sets
          involving fewer than $k$ positive edges\cite{eswaran_augmentation_1976}), or if the PCC has $k$ or fewer
          nodes and the union of positive and incomparable edges is a complete graph.

    \item negative-redundancy --- % 
        A pair of PCCs $C$ and $D$ is $k$-negative-redundant if there are $k$ negative edges between $C$ and $D$,
        or if either PCC has fewer than $k$ nodes and there are at least $\mathop{max}(|C|, |D|)$ negative edges
        between them.
        
    %which can be determined in $O(n_1 n_2)$ time.
    %(by looping over adjacency sets of nodes
    %in $C$ and performing set intersection with nodes in $D$ to get the edges
    %between $C$ and $D$).

    %$k$-negative-redundant if there are $k$ negative edges between them.
\end{enumln}
\kredun{}

The example in \cref{fig:kredun} illustrates different levels of redundancy.
To understand these criteria better, consider what it means for a PCC that has been determined to be
  $k$-positive-redundant to have an undiscovered error.
The error means that the PCC really should be split into (at least) two separate PCCs.
Suppose these PCCs correspond to animals $C$ and $D$.
If the combined PCC is $k$-positive-redundant then are $k$ separate undiscovered mistakes connecting $C$ and $D$,
  and no negative edges.
This may be plausible if $C$ were identical twins, but these tend not to occur for species where the
  distinguishing markings (\eg{} hip and shoulder of zebras) are mostly random.
In other words, an error only becomes undiscoverable if a reviewer makes the same mistake $k$ times.
Note that $k$ can be different for positive and negative redundancy, but in our current implementation we use
  $k=2$ for both positive and negative redundancy.


\subsection{Checking redundancy}

Determining that a PCC with $n$ nodes and $m$ edges is $k$-positive-redundant is equivalent to determining if it
  is $k$-edge-connected if the PCC contains more than $k$ nodes.
Otherwise we just check if it is fully connected.
The special case of $2$-edge-connectivity is also called bridge-connectivity, and this can be determined in %
$O(n + m)$~\cite{eswaran_augmentation_1976,wang_simple_2015}.
For $k>2$, edge connectivity can be generally be determined in $O(mn)$ \cite{esfahanian_connectivity_2017}.
Determining if two components $C$ and $D$ with sizes $n_1$ and $n_2$ are $k$-negative-redundant can be done in
  $O(n_1 n_2)$ time using adjacency lists and set intersections.
%Whenever a positive edge is added inside a PCC, we can check positive-redundancy, and if it is, we can remove all
%  other edges inside that PCC from the priority queue.
%Similarly, when a negative edge is placed between two PCCs, we can check negative redundancy and, if it is
%  satisfied, remove all other edges between those PCCs.

Using this redundancy criteria we are able to implicitly review edges by removing them from the priority queue.
When a positive edge is added within a single PCC, we check for positive-redundancy.
If this passes, all remaining internal edges for that PCC may be removed from the priority queue.
When a negative edge is added between a pair of PCCs, we run the negative-redundancy check on the pair, and if
  this passes, all remaining edges between the PCCs may be removed from the priority queue.
When a positive edge is added between a pair of PCCs, the two PCCs are merged into a single new PCC $C'$, and the
  above negative-redundancy check must be run between $C'$ and all other PCCs having a negative edge connecting to
  $C'$.
It can be shown that if the graph is in a consistent state, that these are the only updates required.

As a final note, consider the case where a PCC is composed of two positive $k$-edge-connected subgraphs joined by
  a single positive edge.
While the entire PCC is not positive redundant, much of it is.
In this case, we should implicitly review all edges within each $k$-edge-connected component by removing them
  from the priority queue.
This can be done dynamically checking when a new edge popped off of the priority queue is within an existing PCC.
We can check if the local-edge-connectivity~\cite{esfahanian_connectivity_2017} between edge's endpoints is at
  least $k$.
If it is, then the edge is part of a $k$-edge-connected component and can be ignored.


\subsection{Redundancy augmentation}\label{subsec:augredun}

In addition to determining if existing edges are redundant, it would be useful determine a small set of edges
  that would make an existing PCC positive-redundant or two PCCs negative-redundant.
Reviewing these edges would help expose any undiscovered errors in the graph.
For negative-redundancy, this is trivial and not discussed.
For positive-redundancy, this is equivalent to the problem of $k$-edge-augmentation.
Turning back to positive-redundancy, when $k=2$ the problem of bridge augmentation can be computed
  $O(m)$~\cite{eswaran_augmentation_1976} as long as all edges in the complement of the PCC can be used in the
  augmentation.
However, if the PCC contains incomparable edges, then these edges cannot be used.
We can address this by using a weighted variant of the problem, setting the weights of the incomparable edges to
  $\inf$, and searching for a minimum cost augmentation.
However, the weighted variant of this problem is NP-hard, even for $k=2$, but can be approximated within a factor
  of $2$~\cite{khuller_approximation_1993}.
We make use of this algorithm later in~\cref{sec:cand}
%We use the augmentation algorithm to generate edges that complete positive redundancy.
%We use the augmentation algorithms to ensure all PCCs are positive consistent without relying on edges returned
%  by the ranking algorithm.

%If the PCC only contains positive edges, edge augmentation with the fewest edges can be computed in linear time
%  using \cite{eswaran_augmentation_1976}.
%However, if some edges in the complement of the positive PCC edges are incomparable then we must compute a
%  minimum weight edge augmentation (which is NP-hard) using a $2$-approximation algorithm
%  \cite{khuller_approximation_1993}.


\section{Recovering from inconsistencies}\label{sec:incon}

In the previous section we described a redundancy criteria that exposes errors by introducing inconsistencies.
In this section we describe an algorithm for fixing these errors and recovering from these inconsistencies.

Whenever a decision is made that either adds a negative edge within a PCC or adds a positive between two PCCs
  with at least one negative edge between them, the graph becomes inconsistent.
In both cases the result is a single PCC $C$ with internal negative edges.
The goal of inconsistency recovery mode is to change the labels of edges in order to make $C$ consistent.
An inconsistency implies that a mistake was made, but does not necessarily determine which edge contains the
  mistake.
Therefore, we develop an algorithm to hypothesize the edge(s) most likely to contain the mistake(s) using a
  minimum cut.
An example of an inconsistent PCC with hypothesis edges is illustrated in \cref{fig:inconpcc}.

\inconpcc{}

For simplicity we only describe the case where $C$ contains exactly one negative edge, but the general case is
  the same except multicut is used in place of minimum $s$-$t$-cut~\cite{vazirani_approximation_2013}.
The procedure alternates between steps of generating ``mistake hypothesis'' edges, and presenting these to the
  user for review.
The ``hypothesis generation algorithm'' returns a set of negative edges or a set of positive edges, which if
  re-labeled as positive or negative respectively would cause $C$ to become consistent.
The algorithm starts by creating an instance of min-cut using the subgraph of $C$ containing only positive edges
  and the endpoints of the negative edge as the terminal nodes.
The weight of edge is the sum of its initial priority, the number of times that edge was manually reviewed, and
  an integer indicating the confidence of the most recent review (which will be discussed in \cref{sec:decision}).
The minimum cut returns a set of edges that disconnects the terminal nodes.
We compare the total weight of cut positive edges with the weight of the terminal negative edge (weighted using
  the same scheme).
If the positive weight is smaller, the algorithm suggests that the cut positive edges should be relabeled as
  negative.
Otherwise, it suggests that the negative edge should become positive.

The user reviews each edge and the algorithm changes the label of the edge until either the reviewer disagrees
  with the algorithm's suggestion or the review set is empty.
If consistency has not been restored, the algorithm must be repeated.
When this happens, the weights of the re-reviewed edges are increased by $1$, forcing the algorithm to look
  elsewhere for a cut.
This repeats until all inconsistencies are eliminated.

%If this results in splitting one PCC into two or more, then the
%positive-redundancy and negative-redundancy tests must be repeated, potentially
%re-adding edges to the priority queue.

Fixing inconsistencies can result in splitting $C$ into multiple PCCs.
This may invalidate implicit reviews inferred from redundancy either within or incident to this subgraph.
Therefore we recompute positive-redundancy within each new PCC, implicitly reviewing edges where the criteria is
  satisfied and re-prioritizing unreviewed edges where it is no longer valid.
A similar process happens for negative-redundancy between each pair of new PCCs as well as between each new PCC
  and all other PCCs previously negative-redundant with $C$.


%The algorithm starts by creating an instance of the multicut~\cite{vazirani_approximation_2013} using the
  %subgraph of $C$ containing only positive edges.
%Each edge is weighted by its assigned positive pairwise probability plus the number of times that edge was
  %manually reviewed.
%The terminal pairs are the negative edges.
%A feasible multicut returns a subset of  that disconnects all terminal pairs.
%Multicut is NP-hard, but it can be approximated by taking the union of min-cuts between each terminal pair.
%To transform the multicut into a mistake hypothesis, we compare the total weight of cut positive edges with the
  %total weight of the terminal negative edges (weighted using the same scheme).
%If positive weight is smaller we suggest that the cut positive edges should be relabeled as negative.
%Otherwise, we suggest the negative edges should be relabeled as positive.

%Inconsistency recovery proceeds as follows.
%Generate a mistake hypothesis, and order the edges by positive probability.
%Present each edge hypothesis to the user in order.
%If the user agrees with the hypothesis, then change the edge label, increment its review count, and continue.
%If the user disagrees, then generate a new hypothesis (using new weights and labels) and restart.
%It can be shown that this process is guaranteed to converge on a consistent graph state.
%Once $C$ is consistent, re-add it to $G$ and return to the main loop.


\section{Candidate edge generation and priorities}\label{sec:cand}

In this section we describe the first step of the algorithm where candidate edges are generated and then
  prioritized for review.
To generate candidate edges that may merge existing PCCs, we issue each annotation as a query to the ranking
  algorithm (the LNBNN algorithm from \cref{chap:ranking}), and form edges from the top results of the ranked
  lists.
In addition we can use the positive PCC augmentation algorithm from~\cref{subsec:augredun} to generate edges that
  would ensure all PCCs are positive redundant.
In practice we alternate between these two modes in each iteration of the outer loop, first searching for merges,
  and then ensuring redundancy.

We then assign a priority to each new candidate edge.
We use the pairwise algorithm from~\cref{chap:pairclf} to estimate the positive, negative, and incomparable
  probabilities of each edge.
Any edge whose maximum probability is above the threshold for automatic decision making is ranked according to
  this probability.
All other edges are ordered by their positive probability.
This ensures automatic decision making is first, followed by an ordering of the edges needed for manual review
  that are most likely to be positive and therefore add the most information to the graph.
It is desirable to add positive decisions to the graph first because
(1) they are the most important edges with respect to determining the animal identities, and
(2) larger PCCs increase the number of edges that can be invalided by positive and negative reviews using the
  redundancy criteria.

%As edges are popped from the priority queue, we  of the queue

%  local edge connectivity \cite{esfahanian_connectivity_2017}

%In the case where the positive-redundancy criteria specifies $k=1$, the order positive edges are added in does
%  not matter because all PCCs will be trees and all trees with $n$ vertices have $n-1$ edges.
%Therefore, the optimal priority scheme simply orders manually reviewed edges by positive probability.
%However, if $k>1$ the priority scheme that minimizes the number of reviews is unclear and is an open question.
%This is partially because edge-augmentation where some edges may not be feasible is NP-hard
%  \cite{khuller_approximation_1993}.
%Even so, if the PCCs were known ahead of time approximation algorithms could be used, but the fact that they are
%  not makes this problem difficult and an interesting topic for future research.
%One possible solution might involve prioritizing edges based on a combination of their probability and current
%  positive degree.
%Another might attempt to review edges to achieve $1$-positive-redundancy and establish the PCCs while preferring
%  to add positive edges to existing chains, then once $1$-positive-redundancy was achieved the algorithm could
%  increase $k$ and find candidate edges using augmentation approximation algorithms.


%Whenever the refresh criteria triggers we perform another loop to complete the positive redundancy of all PCCs.
%This is done to discover split cases before the ranking algorithm is re-executed.
%In this loop the candidate edges are generated by computing an edge-connected augmentation on each PCC.
%If the PCC only contains positive edges, edge augmentation with the fewest edges can be computed in linear time
%  using \cite{eswaran_augmentation_1976}.
%However, if some edges in the complement of the positive PCC edges are incomparable then we must compute a
%  minimum weight edge augmentation (which is NP-hard) using a $2$-approximation algorithm
%  \cite{khuller_approximation_1993}.

\section{Making decisions}\label{sec:decision}

Now that we have generate and prioritized a set of candidate edges we come to the core of the inner loop ---
  decision making.
Because of the surrounding structure of the graph framework, this step is quite simple.
Given a popped edge from the priority queue, we check if any of the positive, negative, and incomparable state
  probabilities are produced by the pairwise algorithm is above their automatic decision threshold (set externally
  as a hyperparameter).
If the edge cannot be automatically reviewed we issue a request for user feedback.
Once we have obtained feedback for an edge --- either automatically or manually --- the edge is added added to
  the appropriate edge set.
After the new edge is added, we update candidate edge priorities discussed in~\cref{sec:redun}.
If the new edge causes an inconsistency we drop into inconsistency mode as discussed in~\cref{sec:incon}.

For each decision we record a user-id to identify the reviewer or algorithm making the decision.
We also follow the approach of~\cite{branson_visual_2010} and store a user-specified categorical confidence value
  of unspecified, guessing, not-sure, pretty-sure, and absolutely-sure (with associated integer values $0$, $1$,
  $2$, $3$, and $4$).
The user-id maintains data provenance allows us to check the automatic verification algorithm, but is not
  directly used in this algorithm description.
However, the user confidence contributes to the edges weights in the error detection and recovery algorithm
  from~\cref{sec:incon}.


%\section{Refreshing candidate edges}\label{sec:refresh}


%The goal is to refresh if there has been a significant number of positive reviews, but new results are consistently
%negative. If we have not found any positive edges then we do not want to refresh. We keep track of the fraction of
%positive review decisions as a moving average of manual decisions. We also maintain the total number of positive reviews
%made since the last candidate edge generation. Thus the candidate edges are refreshed whenever the number of positive
%reviews is above a threshold and the positive review fraction is below a threshold

%As the last outer iteration of the overall algorithm before convergence, triggered when the LNBNN ranking algorithm
%fails to produce positive edges, candidate edges between untested pairs of annotations are added within PCCs that are
%not positive-redundant and between PCCs that are not negative-redundant. This is because the ranking algorithm itself is
%imperfect and the missed matches tend to affect small PCCs disproportionately, which are the last to satisfy redundancy
%tests.


%\subsection{Probabilistic convergence}
%The goal of probabilistic convergence is to determine if a PCC $C$ is negative-redundant with all other components with
%high probability. When all components are positive-redundant and satisfy this, then all edges will be removed from the
%priority queue and the algorithm will converge. We consider the probability $\Pr{E_c \given \nT_C}$ that an undiscovered
%positive edge exists ($E_C$) given $C$'s existing set of outgoing negative edges ($\nT_C$). Under mild conditions (if we
%assume that $\Pr{E_c \given \nT_C} < .5$), we can show that the probability $\Pr{\nT_C \given E_C}$ of observing the
%negative edges bounds this p given that an undiscovered match exists can be used as a surrogate. We can learn this
%probability offline by measuring the frequency that correct results are at a given rank in a PCC's ranked list
%(constructed by aggregating the ranked lists of all annotations in the PCC).

%To predict $\Pr{\nT_C \given E_C}$ we issue all queries as a single LNBNN query to obtain a single ranked list for the
%entire PCC. This can be done by treating all query descriptors as if they were the from the same annotation except
%during the spatial verification stage. Let $R_C$ denote the ranks of every PCC marked as negative with $C$. In an
%offline step we learn a probability mass function $\phi$ that predicts the probability that a correct match appears at a
%given rank for the PCC $C$. The predicted probability is %
%$\Pr{\nT_C \given E_C} = 1 - \sum_{r \in R_C} \phi(r)$.

%To learn $\phi$, we measure the probability that a correct match appears at a given rank, given a correct match exists.
%To do this initialize an histogram. For each $C$ in the training set, divide it into a query $C_q$ and target $C_t$. The
%target and the rest of the PCCs in the training set become database PCCs. Use LNBNN to score each annotation in $C_q$
%against the database PCCs. Determine the best rank that $C_t$ appears in each ranked list, and increment the
%corresponding index in the histogram. Repeat this process for all PCCs in the training set and for multiple partitions
%of each PCC. Normalizing the histogram array results in the PMF $\phi$. In order to prevent marginalization across
%important attributes (such as the number of exemplars in a PCC), construct multiple PMFs for different numbers of
%exemplars in a query.


\section{Refresh and termination criteria}\label{sec:converge}


In this section we discuss the criteria we use for both determining when to refresh candidate edges as well as
  when to stop the algorithm altogether.
We first consider the need for a refresh criteria.
As the review algorithm proceeds, we should only continue manually review as long as the algorithm is
  consistently generating edges that --- once reviewed (typically as positive) --- change the PCCs.
However, at some point the candidate edges may no longer contain positive results, but undiscovered positive
  matches may still exist.
This is because LNBNN, working initially with each annotation having a separate label, can miss more subtle but
  correct matches, especially when there are several annotations for an animal and subtle viewpoints.
As the labeling improves, so does the reliability of the LNBNN.
This issue can be addressed by predicting if none of the remaining edges would change the PCCs, and then
  recomputing candidate edges when this happens.

Similar to the refresh criteria, we must be able to determine when to terminate the algorithm.
Ideally, the algorithm would terminate only when it was certain that all PCCs have been correctly identified.
The graph framework can deterministically achieve this by using all $|V|^2$ edges as candidates and then looping
  until each PCC is positive redundant and each pair of PCCs is negative redundant.
Unfortunately, this requires $O(|V|^2)$ reviews, which is only feasible if
(1) the number of annotations is very small, or
(2) all edges can be automatically reviewed (even then the cost can be prohibitive).
Therefore, in practical circumstances, we turn towards probabilistic methods to determine when to stop.
Like, the refresh criteria, this can be determined --- in part --- by predicting if new reviews will change the
  PCCs.

\subsection{Convergence as a Poisson process}

Both the review and termination criteria can be addressed by considering the question:
``Will there be a meaningful review anytime soon?''.
A meaningful review is one that changes the name labeling of the annotations, \ie{} it either merges two PCCs or
  splits one.
During the inner loop of the algorithm, when edges popped from the priority queue no longer consistently result
  in meaningful reviews, the marginal gains from continuing are outweighed by the cost of manual review.
In this circumstance it is best to break out of the inner loop.
Note that if any meaningful reviews were made during that loop, we should refresh candidate edges and start a new
  loop because a refresh could result in new high priority meaningful edges.
On the other hand, if no meaningful reviews were made in the loop, then refreshing will have no benefit, and the
  algorithm should terminate.

Thus the task is construct a criteria that determines when edges on the top of the priority queue are no longer
  meaningful.
In this way we directly address the refresh criteria and indirectly address termination criteria.
This is indirect in the case of the termination criteria because the algorithm simply stops when the cost of
  manual review is too high.
Directly addressing the termination criteria would involve estimating the probability that undiscovered merge and
  split cases exist (which depends on the effectiveness of the algorithm).
Still, even if we could estimate the latter probability the amount of manual effort required to push it towards
  zero would be enormous.


%\newcommand{\M1}{\Pr{M\teq1}}
%\newcommand{\M0}{\Pr{M\teq0}}
%\newcommand{\Mi}{\Pr{M_i\teq1}}
%\newcommand{\PT}{\Pr{T\teq1}}
%\newcommand{\T}{\Pr{T\teq1}}

Based on these observations we estimate the probability that ``there will be a meaningful review soon''.
We define ``soon'' using a patience parameter $a$, defined as the maximum number of non-meaningful consecutive
  reviews that a manual reviewer is willing to do between meaningful reviews.
Let $M\teq1$ be the event that a review is meaningful and $M\teq0$ otherwise.
Because reviews are ordered, denote the meaningfulness of the $i\th$ review as $M_i$, and denote the index of the
  next review as $n$.
Let $T\teq1 \equiv (\M_i\teq1, \exists i \in [n, n + a])$ be the event that any of the next $a$ reviews will be
  meaningful.
Thus, the aforementioned question can be addressed by measuring the probability of the event $T\teq1$ The goal is
  to measure the probability the event $T\teq1$.
We can periodically check if $\Pr{T\teq1}$ is less than a threshold, and if so, we stop the current loop and
  either refresh or terminate.

To estimate $\Pr{T\teq1}$, we model the event $M_i\teq1$ as a Poisson processes, but for this to be appropriate,
  $M_i$ must follow a uniform distribution.
This would be true if the edges were reviewed in a random order.
However, the priority queue orders edges more likely to be meaningful first, causing $M_i$ to follow a right
  skewed long tail distribution and violate Poisson assumptions.
Even so, the use of a Poisson model can be both justified by considering a sliding window along the distribution
  of $M_i$.
Recall that we only need to make predictions about the next $a$ reviews in the future, thus we are only concerned
  with a small window to the right on the distribution.
Because the long tailed distribution is monotonic decreasing, we can use a small window in the past to estimate a
  upper bound on probability of $T\eq1$ in the future.
As the window moves to the right, the interval on the distribution becomes increasingly approximately uniform and
  the tightness of the bound improves and eventually becomes tight.
This is because once the prioritization algorithm cannot distinguish positive from negative cases, the order of
  the remaining reviews becomes random and the Poisson model becomes exactly appropriate.
Thus, the use of a Poisson model with a sliding window allows us to approximate an upper bound on $\Pr{T\teq1}$,
  and the smaller $\Pr{T\teq1}$ is, the more accurate our estimate will be.


\subsection{Details of Poisson convergence}

Having justified its use, we model $M$ as a Poisson process, which is determined by a single parameter $\mu$.
We can measure $\mu$ as the fraction of recently observed manual reviews that were meaningful using an
  exponentially weighted moving window.
We initialize $\mu=1$ to denote that that it is likely that the first review will be meaningful.
Then, after each new review we update the parameter as %
$\mu \leftarrow m \alpha + (1 - \alpha) \mu$, where $m\teq1$ if the review was meaningful and $0$ otherwise.
The exponential decay $\alpha = 2 / (s + 1)$ is determined by a span parameter $s$, which roughly represents the
  number of previous reviews that are significant.
Using this model, the desired probability that any of the next $a$ reviews will be meaningful is %
$\Pr{T\teq1} = 1 - \exp{-\mu  a}$.
The example in \cref{fig:poisson} illustrates the behavior of the criteria using a synthetic dataset.
In this example we use a window span of $s=20$, a patience of $a=20$, and a threshold of $.1$.

\poisson{}
  

%As the last outer iteration of the overall algorithm before convergence, triggered when the LNBNN ranking algorithm
%fails to produce positive edges, candidate edges between untested pairs of annotations are added within PCCs that are
%not positive-redundant and between PCCs that are not negative-redundant. This is because the ranking algorithm itself is
%imperfect and the missed matches tend to affect small PCCs disproportionately, which are the last to satisfy redundancy
%tests.



%Re-estimating the $k\mu$ at each time-step should


\section{Converting existing datasets}\label{sec:rename}

In this section we briefly discuss the problem of applying graph identification to existing databases.
Most datasets used in practice ignore detailed connectivity information and simply associate a name label with a
  database of cropped (or sometimes un-cropped) images.
Because graph identification relies on this detailed connectivity, we must reconstruct it before new images can
  be added.

%While we believe this framework efficiently and effectively addresses common problems in maintaining animal
%  identification datasets, 

To apply graph identification to a previously existing dataset where annotations have been assigned name labels and
connectivity between the annotations is unknown we follow the following process. First we compute the pairwise
probabilities between each pair of annotations labeled with the same name. We automatically review any edge above a
threshold as positive, negative, or incomparable (these may potentially result in inconsistencies). For any unconnected
PCC we compute an edge augmentation to connect the PCC \cite{eswaran_augmentation_1976,khuller_approximation_1993}, and
insert these edges into the graph labeling them as positive but assigning them the confidence of guessing.

It will be common for such datasets to contain errors, we resolve any inconsistent PCCs as normal, but then we search
for additional split cases using the pairwise classifier. In the case that a pairwise classifier does not exist, the
temporary edges defined by the maximum spanning trees can be used to construct one. The main idea is to re-review all
edges where the pairwise classifier prediction disagrees with its assigned match state. Edges are sorted by the
magnitude of the disagreement, but any edge with a confidence of absolutely-sure is ignored. This will present edges
labeled as guessing for the user to re-review. At this point the dataset is in a legal state, where the name labels
correspond to PCCs. The final step is to execute normal graph review in order to find any merge cases and explicitly
label hard negative edges.

It is sometimes desirable new PCCs to keep the old name labels from the original database (\eg{} sometimes ecologists
encoded information in these names). This is a simple matter when the original database contained no mistakes, but when
the original database contains errors care must be taken. We address this problem by seeking to minimize the number of
annotations that have their name label changed from the original dataset. This can be computing by finding a maximum
linear sum assignment using the Munkres algorithm implemented in SciPy~\cite{eric_jones_scipy_2001}. We create a matrix
where each rows represents a group of annotations in the same PCC and each column represents an original name. If there
are more PCCs than original names the columns are padded with extra values. The matrix is first initialized to be
negative infinity representing impossible assignments. Then for each column representing a padded name, we set we its
value to $1$ indicating that each new name could be assigned to a padded name for some small profit. Finally, we encode
both the profit of assigning a new name with an original name and the extra one ensures that these original names are
always preferred over padded names. Let $f_{rc}$ be the number of annotations in row $r$ with an original name of $c$,
and set matrix value $(r, c)$ to $f_{rc} + 1$ if $f_{rc} > 0$. The maximum linear sum assignment of this matrix results
in the optimal consistent assignment of PCCs to original name labels.
  
  
\section{Experiments}\label{sec:graphexpt}

    TODO: make figures for PZ and GZ

    In this section we design an experiment to measure the impact of graph identification on the number of manual
      reviews required to complete identification as well as the accuracy of those identifications.
    Our experiments simulates the semi-automatic identification process from a user's perspective.
    We consider three algorithms:
    (1) our graph identification algorithm,
    (2) a baseline ranking-based protocol, and
    (3) an intermediate ranking protocol that combines the ranking algorithm with pairwise classifier.
    To simulate our algorithms, we model noisy user response using ground-truth data.
    The simulated user returns the ground-truth classification $98\percent$ of the time, making errors
      $2\percent$ of the time uniformly at random.

    The protocol for the graph identification algorithm is defined in \cref{sub:graphalgo}.
    The pairwise classifier, corresponding thresholds, and termination criteria are learned on a disjoint
      training set.
    Because our algorithm is able to handle errors, we set our automatic classification thresholds to achieve a
      false positive rate of $.1\percent$ on a validation set.
    We disable automatic review for incomparable cases due to the small number of labeled training examples.

    The baseline algorithm captures the effect of using a purely rank-based approach for animal identification.
    We first run the ranking algorithm and add the top $5$ results from each query to a list sorted by the LNBNN
      score.
    The user reviews each result in the list sequentially, without regard to the underlying graph structure.
    Once, new reviews determined to no longer be consistently meaningful (using the approach
      from~\cref{sec:converge}), we first prioritize and review edges that would complete positive redundancy.
    Then, if any the name labels of any annotation was changed in the previous iteration, we generate a new
      ranked list and iterate.
    Otherwise, if an entire iteration completes without a change in name labels, we terminate.

    The intermediate protocol will demonstrate the effect of augmenting the baseline algorithm with our pairwise
      classifier.
    The procedure is the exactly the same as the baseline algorithm, except that any item with a predicted
      probability above a threshold is automatically reviewed.
    Because this approach has no mechanism for error recovery, we choose conservative classification thresholds
      that achieve a $0\percent$ false positive rate on a validation dataset.

    In all tests we record two measurements after each review pertaining to accuracy and error.
    (1) The accuracy measurement is the number of merges remaining before all individuals have been identified.
    This is the number of edges in a spanning forest of the ground-truth positive subgraph minus same measurement
      but applied to the subgraph of all correctly predicted positive edges.
    (2) The error measurement is the total number of edges with a predicted state that differs from its
      ground-truth state.

    Results of this test for the graph, intermediate and baseline algorithms are illustrated in \cref{fig:ETE}
      for each dataset.
    These results demonstrate that the algorithms using the pairwise classifier significantly improves the rate
      at which annotations from the same individual are merged.
    However, the graph algorithm better suited to take advantage of the pairwise classifier because it can afford
      to a make initial mistakes and expect to recover from them later.
    The baseline and intermediate algorithm have no mechanism for error recovery, and thus their error steadily
      increases over time.
    In these cases a significant number of individuals will be misidentified.
    These results also demonstrate that the graph algorithm is able to recover from many of these errors.
    We note that the remaining errors might be resolved if more images of individuals involved in those errors
      are added to the system.

 
\section{Conclusion and summary of graph identification}\label{sec:graphconclusion}

TODO

%A nice and important property of the graph identification framework is that it is agnostic to the underlying procedures
%used to generate and review candidate edges to be placed in the decision graph. Throughout this chapter we will have
%used the ranking algorithm from \cref{chap:ranking}, and the semi-automatic verification algorithm from
%\cref{chap:pairclf}, which work well for distinctively textured species like zebras, giraffes, jaguars, and lionfish.
%However, the benefits of graph identification algorithm could be realized for less textured species such as humpbacks
%whales or bottlenose dolphins by simply using existing contour-based ranking algorithms and a manual reviewer.

%The framework requires two external components:
%\begin{enumin}
%    \item a ranking algorithm to search for candidate edges, and
%    \item a verification algorithm (either manual or automatic) that can
%      decide if a pair of annotation is positive, negative, or incomparable.
%  \end{enumin}

%The verification algorithm (which can be a manual reviewer) is what determines if the graph identification
%  algorithm is manual, semi-automatic, or fully-automatic.
%In our experiments we use the ranking algorithm from \cref{chap:ranking}, and the verification algorithm from
%  \cref{chap:pairclf} to construct these components, which work well for
  
%These algorithms could easily be swapped out for other algorithms tuned
%  towards specific species (\eg{} contour-based ranking algorithms for marine
%  species).
%(or any object that can be visually identified).

Furthermore, as more pairwise training data is gathered and maintained using this framework, more sophisticated
  pairwise classifiers trained using deep learning could be applied, perhaps removing the manual component
  completely and resulting in a fully automatic identification algorithm.

Because of this flexibility the graph identification framework generalizes beyond animal identification and could
  be applied to any instance recognition problem using algorithms tuned for those tasks under the condition that
one annotation corresponds to one individual object (note the photobomb classifier or a segmentation mask can be
  used to relax this
  constraint).
